{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21550,"status":"ok","timestamp":1638352048478,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"tIbffa2CMy9c","outputId":"e31b2095-8716-4ca4-c52b-8bcc528ae140"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_8322/1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2001,"status":"ok","timestamp":1638352050475,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"askoN0AHP7SH","outputId":"75f7827c-c4ee-4f6b-94af-876221ce71e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/comp4471/project/BPPNet-Back-Projected-Pyramid-Network\n"]}],"source":["%cd /content/drive/MyDrive/comp4471/project/BPPNet-Back-Projected-Pyramid-Network"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":29719,"status":"ok","timestamp":1638352086471,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"NDk-YhRbPxSw","outputId":"1da739bf-8edf-4d71-f2be-52b3cc19896b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: asn1crypto==1.2.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 1)) (1.2.0)\n","Requirement already satisfied: certifi==2019.11.28 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 2)) (2019.11.28)\n","Requirement already satisfied: cffi==1.13.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 3)) (1.13.0)\n","Requirement already satisfied: chardet==3.0.4 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 4)) (3.0.4)\n","Requirement already satisfied: cryptography==2.8 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 7)) (2.8)\n","Requirement already satisfied: Django==2.2.5 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 8)) (2.2.5)\n","Requirement already satisfied: docopt==0.6.2 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 9)) (0.6.2)\n","Requirement already satisfied: future==0.18.2 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 10)) (0.18.2)\n","Requirement already satisfied: idna==2.8 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 11)) (2.8)\n","Requirement already satisfied: mime==0.1.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 12)) (0.1.0)\n","Collecting numpy==1.18.1\n","  Using cached numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n","Requirement already satisfied: opencv-python==4.1.2.30 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 14)) (4.1.2.30)\n","Requirement already satisfied: pipreqs==0.4.10 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 15)) (0.4.10)\n","Requirement already satisfied: pycosat==0.6.3 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 16)) (0.6.3)\n","Requirement already satisfied: pycparser==2.19 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 17)) (2.19)\n","Requirement already satisfied: PyJWT==1.7.1 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 18)) (1.7.1)\n","Requirement already satisfied: pyOpenSSL==19.0.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 19)) (19.0.0)\n","Requirement already satisfied: PySocks==1.7.1 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 20)) (1.7.1)\n","Requirement already satisfied: pytz==2019.3 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 21)) (2019.3)\n","Requirement already satisfied: requests==2.22.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 22)) (2.22.0)\n","Requirement already satisfied: ruamel-yaml==0.15.46 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 23)) (0.15.46)\n","Requirement already satisfied: six==1.12.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 24)) (1.12.0)\n","Requirement already satisfied: sqlparse==0.3.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 25)) (0.3.0)\n","Requirement already satisfied: tqdm==4.36.1 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 26)) (4.36.1)\n","Requirement already satisfied: twilio==6.35.2 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 27)) (6.35.2)\n","Requirement already satisfied: urllib3==1.24.2 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 28)) (1.24.2)\n","Requirement already satisfied: yarg==0.1.9 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 29)) (0.1.9)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.2\n","    Uninstalling numpy-1.21.2:\n","      Successfully uninstalled numpy-1.21.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pyrender 0.1.45 requires freetype-py, which is not installed.\n","pyrender 0.1.45 requires pyglet>=1.4.10, which is not installed.\n","pyrender 0.1.45 requires PyOpenGL==3.1.0, which is not installed.\n","pyrender 0.1.45 requires trimesh, which is not installed.\u001b[0m\n","Successfully installed numpy-1.18.1\n"]}],"source":["!pip install -r Requirements.txt"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":8015,"status":"ok","timestamp":1638352097909,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"QJPU0tPrAAAi"},"outputs":[],"source":["import os\n","import cv2\n","import PIL\n","import glob\n","import torch\n","import scipy\n","import random\n","import shutil\n","import numpy as np\n","import pandas as pd\n","from math import exp\n","import torch.nn as nn\n","from PIL import Image\n","from tqdm import tqdm\n","from scipy import ndimage\n","import torch.optim as optim\n","from sklearn import metrics\n","from torch.utils import data\n","from sklearn import datasets\n","from skimage.io import imsave\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F3\n","import torch.nn.functional as F9\n","from sklearn import linear_model\n","from skimage.feature import canny\n","from torch.autograd import Variable\n","import torchvision.models as models\n","from collections import OrderedDict\n","from torch.autograd import Variable\n","from matplotlib.pyplot import imshow\n","from matplotlib import pyplot as plt1\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import KFold\n","from IPython.display import display, Image\n","from skimage.color import lab2rgb, rgb2lab\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as F\n","import torchvision.transforms.functional as F6\n","import torchvision.transforms.functional as F7\n","from sklearn.preprocessing import OneHotEncoder \n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error,r2_score\n","from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n","from sklearn.model_selection import cross_val_score, cross_val_predict"]},{"cell_type":"markdown","metadata":{"id":"3OcaGLs7bOiE"},"source":["Defining our generator (UNet)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":1368,"status":"ok","timestamp":1638352104172,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"uPQd3FlmAAAk"},"outputs":[],"source":["class UNet(nn.Module):\n","\n","    def __init__(self, in_channels=3, out_channels=3, init_features=32):\n","        super(UNet, self).__init__()\n","\n","        features = init_features\n","        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n","        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n","        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n","\n","        self.upconv4 = nn.ConvTranspose2d(\n","            features * 16, features * 8, kernel_size=2, stride=2\n","        )\n","        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n","        self.upconv3 = nn.ConvTranspose2d(\n","            features * 8, features * 4, kernel_size=2, stride=2\n","        )\n","        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n","        self.upconv2 = nn.ConvTranspose2d(\n","            features * 4, features * 2, kernel_size=2, stride=2\n","        )\n","        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n","        self.upconv1 = nn.ConvTranspose2d(\n","            features * 2, features, kernel_size=2, stride=2\n","        )\n","        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n","\n","        self.conv = nn.Conv2d(\n","            in_channels=features, out_channels=out_channels, kernel_size=1\n","        )\n","\n","        self.conv_1 = nn.Conv2d(\n","            in_channels=128, out_channels=out_channels, kernel_size=1\n","        )\n","\n","        self.pyramid_3 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=3, padding=1),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_5 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=5, padding=2),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_7 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=7, padding=3),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_11 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=11, padding=5),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_17 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=17, padding=8),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_25 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=25, padding=12),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_35 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=35, padding=17),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_45 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=45, padding=22),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","    def forward(self, x):\n","\n","        #block1\n","        enc1 = self.encoder1(x)\n","        enc2 = self.encoder2(self.pool1(enc1))\n","        enc3 = self.encoder3(self.pool2(enc2))\n","        enc4 = self.encoder4(self.pool3(enc3))\n","\n","        bottleneck = self.bottleneck(self.pool4(enc4))\n","\n","        dec4 = self.upconv4(bottleneck)\n","        dec4 = torch.cat((dec4, enc4), dim=1)\n","        dec4 = self.decoder4(dec4)\n","        dec3 = self.upconv3(dec4)\n","        dec3 = torch.cat((dec3, enc3), dim=1)\n","        dec3 = self.decoder3(dec3)\n","        dec2 = self.upconv2(dec3)\n","        dec2 = torch.cat((dec2, enc2), dim=1)\n","        dec2 = self.decoder2(dec2)\n","        dec1 = self.upconv1(dec2)\n","        dec1 = torch.cat((dec1, enc1), dim=1)\n","        dec1 = self.decoder1(dec1)\n","        coonv1_1 = self.conv(dec1)\n","\n","        \n","        #block2 \n","        enc1_2 = self.encoder1(coonv1_1)\n","        enc2_2 = self.encoder2(self.pool1(enc1_2))\n","        enc3_2 = self.encoder3(self.pool2(enc2_2))\n","        enc4_2 = self.encoder4(self.pool3(enc3_2))\n","\n","        bottleneck_2 = self.bottleneck(self.pool4(enc4_2))\n","\n","        dec4_2 = self.upconv4(bottleneck_2)\n","        dec4_2 = torch.cat((dec4_2, enc4_2), dim=1)\n","        dec4_2 = self.decoder4(dec4_2)\n","        dec3_2 = self.upconv3(dec4_2)\n","        dec3_2 = torch.cat((dec3_2, enc3_2), dim=1)\n","        dec3_2 = self.decoder3(dec3_2)\n","        dec2_2 = self.upconv2(dec3_2)\n","        dec2_2 = torch.cat((dec2_2, enc2_2), dim=1)\n","        dec2_2 = self.decoder2(dec2_2)\n","        dec1_2 = self.upconv1(dec2_2)\n","        dec1_2 = torch.cat((dec1_2, enc1_2), dim=1)\n","        dec1_2 = self.decoder1(dec1_2)\n","        coonv1_2 = self.conv(dec1_2)\n","\n","\n","        \n","        #block3\n","        enc1_3 = self.encoder1(coonv1_2)\n","        enc2_3 = self.encoder2(self.pool1(enc1_3))\n","        enc3_3 = self.encoder3(self.pool2(enc2_3))\n","        enc4_3 = self.encoder4(self.pool3(enc3_3))\n","\n","        bottleneck_3 = self.bottleneck(self.pool4(enc4_3))\n","\n","        dec4_3 = self.upconv4(bottleneck_3)\n","        dec4_3 = torch.cat((dec4_3, enc4_3), dim=1)\n","        dec4_3 = self.decoder4(dec4_3)\n","        dec3_3 = self.upconv3(dec4_3)\n","        dec3_3 = torch.cat((dec3_3, enc3_3), dim=1)\n","        dec3_3 = self.decoder3(dec3_3)\n","        dec2_3 = self.upconv2(dec3_3)\n","        dec2_3 = torch.cat((dec2_3, enc2_3), dim=1)\n","        dec2_3 = self.decoder2(dec2_3)\n","        dec1_3 = self.upconv1(dec2_3)\n","        dec1_3 = torch.cat((dec1_3, enc1_3), dim=1)\n","        dec1_3 = self.decoder1(dec1_3)\n","        coonv1_3 = self.conv(dec1_3)\n","\n","\n","        #block4\n","        enc1_4 = self.encoder1(coonv1_3)\n","        enc2_4 = self.encoder2(self.pool1(enc1_4))\n","        enc3_4 = self.encoder3(self.pool2(enc2_4))\n","        enc4_4 = self.encoder4(self.pool3(enc3_4))\n","\n","        bottleneck_4 = self.bottleneck(self.pool4(enc4_4))\n","\n","        dec4_4 = self.upconv4(bottleneck_4)\n","        dec4_4 = torch.cat((dec4_4, enc4_4), dim=1)\n","        dec4_4 = self.decoder4(dec4_4)\n","        dec3_4 = self.upconv3(dec4_4)\n","        dec3_4 = torch.cat((dec3_4, enc3_4), dim=1)\n","        dec3_4 = self.decoder3(dec3_4)\n","        dec2_4 = self.upconv2(dec3_4)\n","        dec2_4 = torch.cat((dec2_4, enc2_4), dim=1)\n","        dec2_4 = self.decoder2(dec2_4)\n","        dec1_4 = self.upconv1(dec2_4)\n","        dec1_4 = torch.cat((dec1_4, enc1_4), dim=1)\n","        dec1_4 = self.decoder1(dec1_4)\n","        coonv1_4 = self.conv(dec1_4)\n","\n","        #concatenation of different UNet feature maps\n","        concat = torch.cat((coonv1_1, coonv1_2, coonv1_3, coonv1_4  ), dim=1)\n","\n","\n","        #pyramid convolution\n","        conv_pyramid_3 =  self.pyramid_3(concat)\n","        conv_pyramid_5 =  self.pyramid_5(concat)\n","        conv_pyramid_7 =  self.pyramid_7(concat)\n","        conv_pyramid_11 =  self.pyramid_11(concat)\n","        conv_pyramid_17 =  self.pyramid_17(concat)\n","        conv_pyramid_25 =  self.pyramid_25(concat)\n","        conv_pyramid_35 =  self.pyramid_35(concat)\n","        conv_pyramid_45 =  self.pyramid_45(concat)\n","\n","        #concatenation of feature maps corresponding different convolution filters present in Pyramid convolution layer\n","        concat_py = torch.cat(( conv_pyramid_3, conv_pyramid_5, conv_pyramid_7, conv_pyramid_11, conv_pyramid_17, conv_pyramid_25, conv_pyramid_35, conv_pyramid_45), dim=1)\n","      \n","        return torch.sigmoid(self.conv_1(concat_py))\n","\n","    @staticmethod\n","    def _block(in_channels, features, name):\n","        return nn.Sequential(\n","            OrderedDict(\n","                [\n","                    (\n","                        name + \"conv1\",\n","                        nn.Conv2d(\n","                            in_channels=in_channels,\n","                            out_channels=features,\n","                            kernel_size=3,\n","                            padding=1,\n","                            bias=False,\n","                        ),\n","                    ),\n","                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n","                    (name + \"relu1\", nn.ReLU(inplace=True)),\n","                    (\n","                        name + \"conv2\",\n","                        nn.Conv2d(\n","                            in_channels=features,\n","                            out_channels=features,\n","                            kernel_size=3,\n","                            padding=1,\n","                            bias=False,\n","                        ),\n","                    ),\n","                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n","                    (name + \"relu2\", nn.ReLU(inplace=True)),\n","                ]\n","            )\n","        )"]},{"cell_type":"markdown","metadata":{"id":"ZzLeMds8bglC"},"source":["Defining our Discriminator"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":421,"status":"ok","timestamp":1638352107082,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"Zk5I8Q_mAAAm"},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, in_channels, use_sigmoid=True, use_spectral_norm=True):\n","        super().__init__()\n","        self.use_sigmoid = use_sigmoid\n","\n","        self.conv1 = self.features = nn.Sequential(\n","            spectral_norm(nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","        self.conv2 = nn.Sequential(\n","            spectral_norm(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","        self.conv3 = nn.Sequential(\n","            spectral_norm(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","        self.conv4 = nn.Sequential(\n","            spectral_norm(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","        self.conv5 = nn.Sequential(\n","            spectral_norm(nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n","        )\n","\n","\n","    def forward(self, x):\n","        conv1 = self.conv1(x)\n","        conv2 = self.conv2(conv1)\n","        conv3 = self.conv3(conv2)\n","        conv4 = self.conv4(conv3)\n","        conv5 = self.conv5(conv4)\n","\n","        outputs = conv5\n","        if self.use_sigmoid:\n","            outputs = torch.sigmoid(conv5)\n","\n","        return outputs, [conv1, conv2, conv3, conv4, conv5]\n","\n","def spectral_norm(module, mode=True):\n","    if mode:\n","        return nn.utils.spectral_norm(module)\n","\n","    return module"]},{"cell_type":"markdown","metadata":{"id":"pqRl8shQbkm_"},"source":["Defining our loss functions"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1638352110739,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"0FLH3Z9lAAAo"},"outputs":[],"source":["class AdversarialLoss(nn.Module):\n","    r\"\"\"\n","    Adversarial loss\n","    https://arxiv.org/abs/1711.10337\n","    \"\"\"\n","\n","    def __init__(self, type='hinge', target_real_label=1.0, target_fake_label=0.0):\n","        r\"\"\"\n","        type = nsgan | lsgan | hinge\n","        \"\"\"\n","        super().__init__()\n","\n","        self.type = type\n","        self.register_buffer('real_label', torch.tensor(target_real_label))\n","        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n","\n","        if type == 'nsgan':\n","            self.criterion = nn.BCELoss()\n","\n","        elif type == 'lsgan':\n","            self.criterion = nn.MSELoss()\n","\n","        elif type == 'hinge':\n","            self.criterion = nn.ReLU()\n","\n","    def __call__(self, outputs, is_real, is_disc=None):\n","        if self.type == 'hinge':\n","            if is_real:\n","              return -torch.log(outputs).mean()\n","            else:\n","              return -torch.log(1-outputs).mean()\n","\n","\n","        else:\n","            labels = (self.real_label if is_real else self.fake_label).expand_as(outputs)\n","            loss = self.criterion(outputs, labels)\n","            return loss\n","\n","\n","\n","class ContentLoss(nn.Module):\n","    r\"\"\"\n","    Perceptual loss, VGG-based\n","    https://arxiv.org/abs/1603.08155\n","    https://github.com/dxyang/StyleTransfer/blob/master/utils.py\n","    \"\"\"\n","\n","    def __init__(self, weights=[1.0, 1.0, 1.0, 1.0, 1.0]):\n","        super().__init__()\n","        self.add_module('vgg', VGG19().cuda())\n","        self.criterion = torch.nn.L1Loss().cuda()\n","        self.weights = weights\n","\n","    def __call__(self, x, y):\n","        # Compute features\n","        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n","\n","        content_loss = 0.0\n","        content_loss += self.weights[0] * self.criterion(x_vgg['relu1_1'], y_vgg['relu1_1'])\n","        content_loss += self.weights[1] * self.criterion(x_vgg['relu2_1'], y_vgg['relu2_1'])\n","        content_loss += self.weights[2] * self.criterion(x_vgg['relu3_1'], y_vgg['relu3_1'])\n","        content_loss += self.weights[3] * self.criterion(x_vgg['relu4_1'], y_vgg['relu4_1'])\n","        content_loss += self.weights[4] * self.criterion(x_vgg['relu5_1'], y_vgg['relu5_1'])\n","\n","\n","        return content_loss\n","\n","\n","\n","class VGG19(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        features = models.vgg19(pretrained=True).features\n","        self.relu1_1 = torch.nn.Sequential()\n","        self.relu1_2 = torch.nn.Sequential()\n","\n","        self.relu2_1 = torch.nn.Sequential()\n","        self.relu2_2 = torch.nn.Sequential()\n","\n","        self.relu3_1 = torch.nn.Sequential()\n","        self.relu3_2 = torch.nn.Sequential()\n","        self.relu3_3 = torch.nn.Sequential()\n","        self.relu3_4 = torch.nn.Sequential()\n","\n","        self.relu4_1 = torch.nn.Sequential()\n","        self.relu4_2 = torch.nn.Sequential()\n","        self.relu4_3 = torch.nn.Sequential()\n","        self.relu4_4 = torch.nn.Sequential()\n","\n","        self.relu5_1 = torch.nn.Sequential()\n","        self.relu5_2 = torch.nn.Sequential()\n","        self.relu5_3 = torch.nn.Sequential()\n","        self.relu5_4 = torch.nn.Sequential()\n","\n","        for x in range(2):\n","            self.relu1_1.add_module(str(x), features[x])\n","\n","        for x in range(2, 4):\n","            self.relu1_2.add_module(str(x), features[x])\n","\n","        for x in range(4, 7):\n","            self.relu2_1.add_module(str(x), features[x])\n","\n","        for x in range(7, 9):\n","            self.relu2_2.add_module(str(x), features[x])\n","\n","        for x in range(9, 12):\n","            self.relu3_1.add_module(str(x), features[x])\n","\n","        for x in range(12, 14):\n","            self.relu3_2.add_module(str(x), features[x])\n","\n","        for x in range(14, 16):\n","            self.relu3_3.add_module(str(x), features[x])\n","\n","        for x in range(16, 18):\n","            self.relu3_4.add_module(str(x), features[x])\n","\n","        for x in range(18, 21):\n","            self.relu4_1.add_module(str(x), features[x])\n","\n","        for x in range(21, 23):\n","            self.relu4_2.add_module(str(x), features[x])\n","\n","        for x in range(23, 25):\n","            self.relu4_3.add_module(str(x), features[x])\n","\n","        for x in range(25, 27):\n","            self.relu4_4.add_module(str(x), features[x])\n","\n","        for x in range(27, 30):\n","            self.relu5_1.add_module(str(x), features[x])\n","\n","        for x in range(30, 32):\n","            self.relu5_2.add_module(str(x), features[x])\n","\n","        for x in range(32, 34):\n","            self.relu5_3.add_module(str(x), features[x])\n","\n","        for x in range(34, 36):\n","            self.relu5_4.add_module(str(x), features[x])\n","\n","        # don't need the gradients, just want the features\n","        for param in self.parameters():\n","            param.requires_grad = False\n","\n","    def forward(self, x):\n","        relu1_1 = self.relu1_1(x)\n","        relu1_2 = self.relu1_2(relu1_1)\n","\n","        relu2_1 = self.relu2_1(relu1_2)\n","        relu2_2 = self.relu2_2(relu2_1)\n","\n","        relu3_1 = self.relu3_1(relu2_2)\n","        relu3_2 = self.relu3_2(relu3_1)\n","        relu3_3 = self.relu3_3(relu3_2)\n","        relu3_4 = self.relu3_4(relu3_3)\n","\n","        relu4_1 = self.relu4_1(relu3_4)\n","        relu4_2 = self.relu4_2(relu4_1)\n","        relu4_3 = self.relu4_3(relu4_2)\n","        relu4_4 = self.relu4_4(relu4_3)\n","\n","        relu5_1 = self.relu5_1(relu4_4)\n","        relu5_2 = self.relu5_2(relu5_1)\n","        relu5_3 = self.relu5_3(relu5_2)\n","        relu5_4 = self.relu5_4(relu5_3)\n","\n","        out = {\n","            'relu1_1': relu1_1,\n","            'relu1_2': relu1_2,\n","\n","            'relu2_1': relu2_1,\n","            'relu2_2': relu2_2,\n","\n","            'relu3_1': relu3_1,\n","            'relu3_2': relu3_2,\n","            'relu3_3': relu3_3,\n","            'relu3_4': relu3_4,\n","\n","            'relu4_1': relu4_1,\n","            'relu4_2': relu4_2,\n","            'relu4_3': relu4_3,\n","            'relu4_4': relu4_4,\n","\n","            'relu5_1': relu5_1,\n","            'relu5_2': relu5_2,\n","            'relu5_3': relu5_3,\n","            'relu5_4': relu5_4,\n","        }\n","        return out"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1638352113016,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"nCVcqVjAAAAr"},"outputs":[],"source":["def gaussian(window_size, sigma):\n","    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n","    return gauss/gauss.sum()\n","\n","def create_window(window_size, channel):\n","    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n","    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n","    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n","    return window\n","\n","def _ssim(img1, img2, window, window_size, channel, size_average = True):\n","    mu1 = F3.conv2d(img1, window, padding = window_size//2, groups = channel)\n","    mu2 = F3.conv2d(img2, window, padding = window_size//2, groups = channel)\n","\n","    mu1_sq = mu1.pow(2)\n","    mu2_sq = mu2.pow(2)\n","    mu1_mu2 = mu1*mu2\n","\n","    sigma1_sq = F3.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n","    sigma2_sq = F3.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n","    sigma12 = F3.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n","\n","    C1 = 0.01**2\n","    C2 = 0.03**2\n","\n","    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n","\n","    if size_average:\n","        return ssim_map.mean()\n","    else:\n","        return ssim_map.mean(1).mean(1).mean(1)\n","\n","class SSIM(torch.nn.Module):\n","    def __init__(self, window_size = 11, size_average = True):\n","        super(SSIM, self).__init__()\n","        self.window_size = window_size\n","        self.size_average = size_average\n","        self.channel = 1\n","        self.window = create_window(window_size, self.channel)\n","\n","    def forward(self, img1, img2):\n","        (_, channel, _, _) = img1.size()\n","\n","        if channel == self.channel and self.window.data.type() == img1.data.type():\n","            window = self.window\n","        else:\n","            window = create_window(self.window_size, channel)\n","            \n","            if img1.is_cuda:\n","                window = window.cuda(img1.get_device())\n","            window = window.type_as(img1)\n","            \n","            self.window = window\n","            self.channel = channel\n","\n","\n","        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n","\n","def ssim(img1, img2, window_size = 11, size_average = True):\n","    (_, channel, _, _) = img1.size()\n","    window = create_window(window_size, channel)\n","    \n","    if img1.is_cuda:\n","        window = window.cuda(img1.get_device())\n","    window = window.type_as(img1)\n","    \n","    return _ssim(img1, img2, window, window_size, channel, size_average)"]},{"cell_type":"markdown","metadata":{"id":"KtvXXCtxboWU"},"source":["Defining our model i.e. DU_Net"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":785,"status":"ok","timestamp":1638352114995,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"SNTpEUunAAAw"},"outputs":[],"source":["class DU_Net(nn.Module):\n","\n","    def __init__(self, unet_input, unet_output, discriminator_input):\n","        super().__init__()\n","\n","\n","        unet = UNet(in_channels=unet_input ,out_channels=unet_output)\n","        unet = nn.DataParallel(unet, device_ids=[0,1])\n","        unet = unet.cuda()\n","\n","        discriminator = Discriminator(in_channels=discriminator_input , use_sigmoid=True)\n","        discriminator = nn.DataParallel(discriminator, device_ids=[0,1])\n","        discriminator = discriminator.cuda()\n","\n","        criterion = nn.MSELoss()\n","        adversarial_loss = AdversarialLoss(type='hinge')\n","        l1_loss = nn.L1Loss()\n","        content_loss = ContentLoss()\n","        ssim = SSIM(window_size = 11)\n","        bce = nn.BCELoss()\n","\n","        self.add_module('unet', unet)\n","        self.add_module('discriminator', discriminator)\n","\n","        self.add_module('criterion', criterion)\n","        self.add_module('adversarial_loss', adversarial_loss)\n","        self.add_module('l1_loss', l1_loss)\n","        self.add_module('content_loss', content_loss)\n","        self.add_module('ssim_loss', ssim)\n","        self.add_module('bce_loss', bce)\n","        \n","\n","        self.unet_optimizer = optim.Adam(\n","            unet.parameters(), \n","            lr = float(0.001),\n","            betas=(0.9, 0.999)\n","            )\n","\n","        self.dis_optimizer = optim.Adam(\n","             params=discriminator.parameters(),\n","             lr=float(0.001),\n","             betas=(0.9, 0.999)\n","             )\n","\n","        self.unet_input = unet_input\n","        self.unet_output = unet_output\n","        self.discriminator_input = discriminator_input\n","\n","\n","    def load(self, path_unet, path_discriminator):\n","        weight_unet = torch.load(path_unet)\n","        weight_discriminator = torch.load(path_discriminator)\n","        self.unet.load_state_dict(weight_unet)\n","        self.discriminator.load_state_dict(weight_discriminator)\n","\n","    def save_weight(self, path_unet, path_dis):\n","        torch.save(self.unet.state_dict(), path_unet)\n","        torch.save(self.discriminator.state_dict(), path_dis)\n","\n","    def process(self, haze_images, dehaze_images):\n","\n","        # zero optimizers\n","        self.unet_optimizer.zero_grad()\n","        self.dis_optimizer.zero_grad()\n","\n","\n","        # find output and initialize loss to zero\n","        unet_loss = 0\n","        dis_loss = 0\n","\n","        outputs = self.unet(haze_images.cuda())\n","\n","        # unet loss\n","        unet_fake, unet_fake_feat = self.discriminator(outputs.cuda())        \n","        unet_gan_loss = self.adversarial_loss(unet_fake, True, False) * 0.7\n","        unet_loss += unet_gan_loss\n","\n","        unet_criterion = self.criterion(outputs.cuda(), dehaze_images.cuda())\n","        unet_loss += unet_criterion\n","\n","\n","\n","\n","        gen_content_loss = self.content_loss(outputs.cuda(), dehaze_images.cuda())\n","        gen_content_loss = (gen_content_loss * 0.7).cuda()\n","        unet_loss += gen_content_loss.cuda()\n","        \n","        \n","        ssim_loss =  self.ssim_loss(outputs.cuda(), dehaze_images.cuda())\n","        ssim_loss = (1-ssim_loss)*2\n","        unet_loss += ssim_loss.cuda()\n","\n","        # discriminator loss\n","        dis_real, dis_real_feat = self.discriminator(dehaze_images.cuda())        \n","        dis_fake, dis_fake_feat = self.discriminator(outputs.detach().cuda())       \n","        dis_real_loss = self.adversarial_loss(dis_real, True, True)\n","        dis_fake_loss = self.adversarial_loss(dis_fake, False, True)\n","        dis_loss += (dis_real_loss + dis_fake_loss) / 2\n","\n","\n","        return unet_loss, dis_loss, unet_criterion, 1-ssim_loss/2\n","\n","    def backward(self, unet_loss, dis_loss):\n","        unet_loss.backward()\n","        self.unet_optimizer.step()\n","        \n","        dis_loss.backward(retain_graph = True)\n","        self.dis_optimizer.step()\n","\n","\n","    def predict(self, haze_images):\n","      predict_mask = self.unet(haze_images.cuda())\n","      return predict_mask"]},{"cell_type":"markdown","metadata":{"id":"d5NG1aLzbtmE"},"source":["Defining our and creating the data loader"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1078,"status":"ok","timestamp":1638352118035,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"B4Zt47MJAAA0","outputId":"d2e4c6d4-f62f-4109-8398-fbf981cb88ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["['O-Haze/train/haze/01_outdoor_hazy.jpg', 'O-Haze/train/haze/02_outdoor_hazy.jpg', 'O-Haze/train/haze/03_outdoor_hazy.JPG', 'O-Haze/train/haze/04_outdoor_hazy.jpg', 'O-Haze/train/haze/05_outdoor_hazy.jpg', 'O-Haze/train/haze/06_outdoor_hazy.jpg', 'O-Haze/train/haze/07_outdoor_hazy.jpg', 'O-Haze/train/haze/08_outdoor_hazy.jpg', 'O-Haze/train/haze/09_outdoor_hazy.jpg', 'O-Haze/train/haze/10_outdoor_hazy.jpg', 'O-Haze/train/haze/11_outdoor_hazy.jpg', 'O-Haze/train/haze/12_outdoor_hazy.jpg', 'O-Haze/train/haze/13_outdoor_hazy.jpg', 'O-Haze/train/haze/14_outdoor_hazy.jpg', 'O-Haze/train/haze/15_outdoor_hazy.jpg', 'O-Haze/train/haze/16_outdoor_hazy.jpg', 'O-Haze/train/haze/17_outdoor_hazy.jpg', 'O-Haze/train/haze/18_outdoor_hazy.jpg', 'O-Haze/train/haze/19_outdoor_hazy.jpg', 'O-Haze/train/haze/20_outdoor_hazy.jpg', 'O-Haze/train/haze/21_outdoor_hazy.JPG', 'O-Haze/train/haze/22_outdoor_hazy.jpg', 'O-Haze/train/haze/23_outdoor_hazy.jpg', 'O-Haze/train/haze/24_outdoor_hazy.jpg', 'O-Haze/train/haze/25_outdoor_hazy.jpg', 'O-Haze/train/haze/26_outdoor_hazy.jpg', 'O-Haze/train/haze/27_outdoor_hazy.jpg', 'O-Haze/train/haze/28_outdoor_hazy.jpg', 'O-Haze/train/haze/29_outdoor_hazy.jpg', 'O-Haze/train/haze/30_outdoor_hazy.jpg', 'O-Haze/train/haze/31_outdoor_hazy.jpg', 'O-Haze/train/haze/32_outdoor_hazy.jpg', 'O-Haze/train/haze/33_outdoor_hazy.jpg', 'O-Haze/train/haze/34_outdoor_hazy.jpg', 'O-Haze/train/haze/35_outdoor_hazy.jpg', 'O-Haze/train/haze/36_outdoor_hazy.jpg', 'O-Haze/train/haze/37_outdoor_hazy.jpg', 'O-Haze/train/haze/38_outdoor_hazy.jpg', 'O-Haze/train/haze/39_outdoor_hazy.jpg', 'O-Haze/train/haze/40_outdoor_hazy.jpg', 'O-Haze/train/haze/41_outdoor_hazy.jpg', 'O-Haze/train/haze/42_outdoor_hazy.jpg', 'O-Haze/train/haze/43_outdoor_hazy.jpg', 'O-Haze/train/haze/44_outdoor_hazy.jpg', 'O-Haze/train/haze/45_outdoor_hazy.jpg']\n","['O-Haze/train/gt/01_outdoor_GT.jpg', 'O-Haze/train/gt/02_outdoor_GT.jpg', 'O-Haze/train/gt/03_outdoor_GT.JPG', 'O-Haze/train/gt/04_outdoor_GT.jpg', 'O-Haze/train/gt/05_outdoor_GT.jpg', 'O-Haze/train/gt/06_outdoor_GT.jpg', 'O-Haze/train/gt/07_outdoor_GT.jpg', 'O-Haze/train/gt/08_outdoor_GT.jpg', 'O-Haze/train/gt/09_outdoor_GT.jpg', 'O-Haze/train/gt/10_outdoor_GT.jpg', 'O-Haze/train/gt/11_outdoor_GT.jpg', 'O-Haze/train/gt/12_outdoor_GT.jpg', 'O-Haze/train/gt/13_outdoor_GT.jpg', 'O-Haze/train/gt/14_outdoor_GT.jpg', 'O-Haze/train/gt/15_outdoor_GT.jpg', 'O-Haze/train/gt/16_outdoor_GT.jpg', 'O-Haze/train/gt/17_outdoor_GT.jpg', 'O-Haze/train/gt/18_outdoor_GT.jpg', 'O-Haze/train/gt/19_outdoor_GT.jpg', 'O-Haze/train/gt/20_outdoor_GT.jpg', 'O-Haze/train/gt/21_outdoor_GT.JPG', 'O-Haze/train/gt/22_outdoor_GT.jpg', 'O-Haze/train/gt/23_outdoor_GT.jpg', 'O-Haze/train/gt/24_outdoor_GT.jpg', 'O-Haze/train/gt/25_outdoor_GT.jpg', 'O-Haze/train/gt/26_outdoor_GT.jpg', 'O-Haze/train/gt/27_outdoor_GT.jpg', 'O-Haze/train/gt/28_outdoor_GT.jpg', 'O-Haze/train/gt/29_outdoor_GT.jpg', 'O-Haze/train/gt/30_outdoor_GT.jpg', 'O-Haze/train/gt/31_outdoor_GT.jpg', 'O-Haze/train/gt/32_outdoor_GT.jpg', 'O-Haze/train/gt/33_outdoor_GT.jpg', 'O-Haze/train/gt/34_outdoor_GT.jpg', 'O-Haze/train/gt/35_outdoor_GT.jpg', 'O-Haze/train/gt/36_outdoor_GT.jpg', 'O-Haze/train/gt/37_outdoor_GT.jpg', 'O-Haze/train/gt/38_outdoor_GT.jpg', 'O-Haze/train/gt/39_outdoor_GT.jpg', 'O-Haze/train/gt/40_outdoor_GT.jpg', 'O-Haze/train/gt/41_outdoor_GT.jpg', 'O-Haze/train/gt/42_outdoor_GT.jpg', 'O-Haze/train/gt/43_outdoor_GT.jpg', 'O-Haze/train/gt/44_outdoor_GT.jpg', 'O-Haze/train/gt/45_outdoor_GT.jpg']\n"]}],"source":["class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, haze_list, dehaze_list, augment=False):\n","        super().__init__()\n","        # print(haze_list)\n","        self.augment = augment\n","        self.haze_list = haze_list\n","        self.dehaze_list = dehaze_list\n","        self.haze_list = sorted(self.haze_list)\n","        self.dehaze_list = sorted(self.dehaze_list)\n","        print(self.haze_list)\n","        print(self.dehaze_list)\n","        \n","    def __len__(self):\n","        # return 45\n","        return 210\n","\n","    def __getitem__(self, index):\n","        try:\n","            item = self.load_item(index)\n","        except:\n","            print('loading error: ' + self.haze_list[index])\n","            item = self.load_item(0)\n","            \n","\n","        return item\n","\n","\n","    def load_item(self, index):\n","        val = 1024*2           #crop size i.e hight and width\n","        size_data = 25         #depends on the no. of training images in the dataset\n","        height_data = 4657     #heigth of the training images\n","        width_data = 2833      #width of the training images\n","\n","        numx = random.randint(0, height_data-val)\n","        numy = random.randint(0, width_data-val)\n","\n","        haze_image = cv2.imread(self.haze_list[index%size_data])\n","        dehaze_image = cv2.imread(self.dehaze_list[index%size_data])\n","        haze_image = Image.fromarray(haze_image)\n","        dehaze_image = Image.fromarray(dehaze_image)\n","\n","        haze_crop=haze_image.crop((numx, numy, numx+val, numy+val))\n","        dehaze_crop=dehaze_image.crop((numx, numy, numx+val, numy+val))\n"," \n","        haze_crop = haze_crop.resize((512,512), resample=PIL.Image.BICUBIC)\n","        dehaze_crop = dehaze_crop.resize((512,512), resample=PIL.Image.BICUBIC)\n","\n","        haze_crop = np.array(haze_crop)\n","        dehaze_crop = np.array(dehaze_crop)\n","        haze_crop = cv2.cvtColor(haze_crop, cv2.COLOR_BGR2YCrCb)\n","        dehaze_crop = cv2.cvtColor(dehaze_crop, cv2.COLOR_BGR2YCrCb)\n","        haze_crop = self.to_tensor(haze_crop).cuda()\n","        dehaze_crop = self.to_tensor(dehaze_crop).cuda()\n","        \n","        return haze_crop.cuda(), dehaze_crop.cuda()\n","    \n","    def to_tensor(self, img):\n","        img_t = F.to_tensor(img).float()\n","        return img_t\n","\n","\n","    def create_iterator(self, batch_size):\n","        while True:\n","            sample_loader = DataLoader(\n","                dataset=self,\n","                batch_size=batch_size,\n","                drop_last=True\n","            )\n","\n","            for item in sample_loader:\n","                yield item\n","\n","\n","path_of_train_hazy_images = 'O-Haze/train/haze/*'\n","path_of_train_gt_images = 'O-Haze/train/gt/*'\n","\n","images_paths_train_gt=glob.glob(path_of_train_gt_images)\n","image_paths_train_hazy=glob.glob(path_of_train_hazy_images)\n","\n","train_dataset = Dataset(image_paths_train_hazy, images_paths_train_gt, augment=False)\n","\n","train_loader = DataLoader(\n","            dataset=train_dataset,\n","            batch_size=2,\n","            num_workers=0,\n","            drop_last=True,\n","            shuffle=False\n","        )"]},{"cell_type":"markdown","metadata":{"id":"DQW0X3g5dNBX"},"source":["Creating the model"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107,"referenced_widgets":["ebe9a67a932540f5915ea51ec0a5270a","f7c88cdd25194de19710363de98990aa","d34e39b5242f4a9da3e0d1bc428b9e13","5fea42f5b82c464895c39da4c89bc001","2182e0fd245b47c6a4b2effc75772271","00bd30886cab4fe682e25a897b7dde9c","39b1407cce964ccc80dde8685c296bb7","b67b16690dc8453faf8c4b5e3866d3db"]},"executionInfo":{"elapsed":45130,"status":"ok","timestamp":1638352164500,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"ZACwe8ObAABE","outputId":"3061fba1-65cd-4e29-f909-bad0ccdf258d"},"outputs":[],"source":["graph_gloss = []\n","input_unet_channel = 3\n","output_unet_channel = 3\n","input_dis_channel = 3\n","max_epochs = 100\n","DUNet = DU_Net(input_unet_channel ,output_unet_channel ,input_dis_channel).cuda()"]},{"cell_type":"markdown","metadata":{"id":"Gb7PvZASdQn1"},"source":["Training function"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1638352205088,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"AFZtJGoY5nu-","outputId":"2762182e-c144-453f-d39d-00cf06fad6fd"},"outputs":[{"data":{"text/plain":["'weight/20211201_lr0.001_generator_0.pth'"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["a = \"weight/{}_generator_{}.pth\".format(\"20211201_lr0.001\", 0)\n","a"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":801,"status":"ok","timestamp":1638352238710,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"24-9evbnAABM"},"outputs":[],"source":["def train(max_epochs, current_epoch=0):\n","    for epoch in range(max_epochs):\n","        i=1\n","        mse_epoch = 0.0\n","        ssim_epoch = 0.0\n","        unet_epoch = 0.0\n","        for haze_images, dehaze_images, in train_loader:\n","            unet_loss, dis_loss, mse, ssim = DUNet.process(haze_images.cuda(), dehaze_images.cuda())\n","            DUNet.backward(unet_loss.cuda(), dis_loss.cuda())\n","            print('Epoch: '+str(epoch+current_epoch+1)+ ' || Batch: '+str(i)+ \" || unet loss: \"+str(unet_loss.cpu().item()) + \" || dis loss: \"+str(dis_loss.cpu().item()) + \" || mse: \"+str(mse.cpu().item()) + \" | ssim:\" + str(ssim.cpu().item()) )\n","            mse_epoch =  mse_epoch + mse.cpu().item() \n","            ssim_epoch = ssim_epoch + ssim.cpu().item()\n","            unet_epoch = unet_epoch + unet_loss.cpu().item()\n","            i=i+1\n","        \n","        print()\n","        mse_epoch = mse_epoch/i\n","        ssim_epoch = ssim_epoch/i\n","        unet_epoch = unet_epoch/i\n","        graph_gloss.append(ssim_epoch)\n","        print(\"mse: + \"+str(mse_epoch) + \" | ssim: \"+ str(ssim_epoch)+ \" | unet:\"+str(unet_epoch))\n","        \n","        weight_dir = 'hj_train_211201_lr0.00001'\n","        if not os.path.exists(weight_dir):\n","            os.mkdir(weight_dir)\n","        path_of_generator_weight = \"{}/generator_{}.pth\".format(weight_dir, epoch + current_epoch)  #path for storing the weights of genertaor\n","        path_of_discriminator_weight = \"{}/discriminator_{}.pth\".format(weight_dir, epoch + current_epoch)  #path for storing the weights of discriminator\n","        \n","        DUNet.save_weight(path_of_generator_weight,path_of_discriminator_weight)\n","        print()"]},{"cell_type":"markdown","metadata":{"id":"29CCGgMDdTPe"},"source":["Calling training function"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":406,"status":"ok","timestamp":1638352253370,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"QneiMAy2UW4N"},"outputs":[],"source":["from PIL import Image"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":171},"id":"rmEpSm9jAABP","outputId":"0f15a3f4-a396-4ca6-f10a-7d8187412b26"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1 || Batch: 1 || unet loss: 3.4743804931640625 || dis loss: 0.6893105506896973 || mse: 0.04383080452680588 | ssim:0.17579913139343262\n","Epoch: 1 || Batch: 2 || unet loss: 2.504474401473999 || dis loss: 1.4490548372268677 || mse: 0.05937793105840683 | ssim:0.3623482584953308\n","Epoch: 1 || Batch: 3 || unet loss: 3.466864585876465 || dis loss: 0.7062281370162964 || mse: 0.044267162680625916 | ssim:0.3583306074142456\n","Epoch: 1 || Batch: 4 || unet loss: 2.463566780090332 || dis loss: 0.7085024118423462 || mse: 0.03114955872297287 | ssim:0.5469833612442017\n","Epoch: 1 || Batch: 5 || unet loss: 1.9666732549667358 || dis loss: 0.7145917415618896 || mse: 0.06368862837553024 | ssim:0.5775719881057739\n","Epoch: 1 || Batch: 6 || unet loss: 2.0168490409851074 || dis loss: 0.7264870405197144 || mse: 0.039217349141836166 | ssim:0.6208686232566833\n","Epoch: 1 || Batch: 7 || unet loss: 1.7907449007034302 || dis loss: 0.8422043323516846 || mse: 0.01882745325565338 | ssim:0.7047438025474548\n","Epoch: 1 || Batch: 8 || unet loss: 1.6124781370162964 || dis loss: 0.8946384191513062 || mse: 0.0302722305059433 | ssim:0.7284281253814697\n","Epoch: 1 || Batch: 9 || unet loss: 1.8169667720794678 || dis loss: 0.7052788734436035 || mse: 0.033169735223054886 | ssim:0.7148013114929199\n","Epoch: 1 || Batch: 10 || unet loss: 2.1862785816192627 || dis loss: 0.6942940950393677 || mse: 0.01796489767730236 | ssim:0.6995574831962585\n","Epoch: 1 || Batch: 11 || unet loss: 1.5042333602905273 || dis loss: 0.8067639470100403 || mse: 0.01408272422850132 | ssim:0.8021984100341797\n","Epoch: 1 || Batch: 12 || unet loss: 1.4542722702026367 || dis loss: 0.8964008688926697 || mse: 0.04253605008125305 | ssim:0.6959489583969116\n","Epoch: 1 || Batch: 13 || unet loss: 1.7908368110656738 || dis loss: 0.7564647197723389 || mse: 0.02615169808268547 | ssim:0.6955399513244629\n","Epoch: 1 || Batch: 14 || unet loss: 1.5396701097488403 || dis loss: 0.5860822200775146 || mse: 0.036986228078603745 | ssim:0.7532979846000671\n","Epoch: 1 || Batch: 15 || unet loss: 1.6482266187667847 || dis loss: 0.6055716276168823 || mse: 0.023360654711723328 | ssim:0.7512184977531433\n","Epoch: 1 || Batch: 16 || unet loss: 1.5127408504486084 || dis loss: 0.6175671815872192 || mse: 0.027274735271930695 | ssim:0.7851896286010742\n","Epoch: 1 || Batch: 17 || unet loss: 1.5774871110916138 || dis loss: 0.8306933641433716 || mse: 0.020207401365041733 | ssim:0.7415715456008911\n","Epoch: 1 || Batch: 18 || unet loss: 1.5685750246047974 || dis loss: 0.8991525173187256 || mse: 0.015144942328333855 | ssim:0.765605092048645\n","Epoch: 1 || Batch: 19 || unet loss: 1.5660713911056519 || dis loss: 0.8374559879302979 || mse: 0.01363158505409956 | ssim:0.7667288780212402\n","Epoch: 1 || Batch: 20 || unet loss: 1.5843192338943481 || dis loss: 0.8724720478057861 || mse: 0.022451281547546387 | ssim:0.7932953834533691\n","Epoch: 1 || Batch: 21 || unet loss: 1.5940165519714355 || dis loss: 0.7793048024177551 || mse: 0.020980482921004295 | ssim:0.7595105171203613\n","Epoch: 1 || Batch: 22 || unet loss: 1.6185166835784912 || dis loss: 0.7756731510162354 || mse: 0.02108841948211193 | ssim:0.7739688158035278\n","Epoch: 1 || Batch: 23 || unet loss: 1.583878517150879 || dis loss: 0.7805670499801636 || mse: 0.014898667111992836 | ssim:0.8114988803863525\n","Epoch: 1 || Batch: 24 || unet loss: 1.4551410675048828 || dis loss: 0.8125436305999756 || mse: 0.012603803537786007 | ssim:0.8285754919052124\n","Epoch: 1 || Batch: 25 || unet loss: 1.4818171262741089 || dis loss: 0.8289748430252075 || mse: 0.01595040038228035 | ssim:0.7978293299674988\n","Epoch: 1 || Batch: 26 || unet loss: 1.5519895553588867 || dis loss: 0.8007429242134094 || mse: 0.02520867809653282 | ssim:0.718970775604248\n","Epoch: 1 || Batch: 27 || unet loss: 1.1295936107635498 || dis loss: 0.8160163164138794 || mse: 0.010990425944328308 | ssim:0.866733729839325\n","Epoch: 1 || Batch: 28 || unet loss: 1.3234928846359253 || dis loss: 0.7770735025405884 || mse: 0.02015206776559353 | ssim:0.8200773000717163\n","Epoch: 1 || Batch: 29 || unet loss: 1.3812702894210815 || dis loss: 0.7802454233169556 || mse: 0.015427425503730774 | ssim:0.8214885592460632\n","Epoch: 1 || Batch: 30 || unet loss: 1.437516689300537 || dis loss: 0.7038397192955017 || mse: 0.03498479351401329 | ssim:0.7204049825668335\n","Epoch: 1 || Batch: 31 || unet loss: 1.397691011428833 || dis loss: 0.7686378955841064 || mse: 0.018111292272806168 | ssim:0.7748970985412598\n","Epoch: 1 || Batch: 32 || unet loss: 1.37229585647583 || dis loss: 0.7570677995681763 || mse: 0.021565183997154236 | ssim:0.7658356428146362\n","Epoch: 1 || Batch: 33 || unet loss: 1.4716572761535645 || dis loss: 0.7991093397140503 || mse: 0.018022602424025536 | ssim:0.8139127492904663\n","Epoch: 1 || Batch: 34 || unet loss: 1.3006441593170166 || dis loss: 0.7874562740325928 || mse: 0.017134658992290497 | ssim:0.7936474680900574\n","Epoch: 1 || Batch: 35 || unet loss: 1.6281375885009766 || dis loss: 0.8106687068939209 || mse: 0.01379903219640255 | ssim:0.7931451797485352\n","Epoch: 1 || Batch: 36 || unet loss: 1.1349756717681885 || dis loss: 0.8158125877380371 || mse: 0.013747056946158409 | ssim:0.8709819316864014\n","Epoch: 1 || Batch: 37 || unet loss: 1.2711632251739502 || dis loss: 0.7984537482261658 || mse: 0.016498059034347534 | ssim:0.7829107046127319\n","Epoch: 1 || Batch: 38 || unet loss: 1.4435231685638428 || dis loss: 0.8007948398590088 || mse: 0.012829814106225967 | ssim:0.7944284677505493\n","Epoch: 1 || Batch: 39 || unet loss: 1.2230726480484009 || dis loss: 0.777816891670227 || mse: 0.012701503932476044 | ssim:0.8073849678039551\n","Epoch: 1 || Batch: 40 || unet loss: 1.191396713256836 || dis loss: 0.7699339389801025 || mse: 0.01458611898124218 | ssim:0.8029515147209167\n","Epoch: 1 || Batch: 41 || unet loss: 1.1685564517974854 || dis loss: 0.7775062322616577 || mse: 0.014585714787244797 | ssim:0.8542477488517761\n","Epoch: 1 || Batch: 42 || unet loss: 1.3736107349395752 || dis loss: 0.7383471727371216 || mse: 0.019000165164470673 | ssim:0.7530869245529175\n","Epoch: 1 || Batch: 43 || unet loss: 1.2959502935409546 || dis loss: 0.7494555711746216 || mse: 0.01583472266793251 | ssim:0.7917229533195496\n","Epoch: 1 || Batch: 44 || unet loss: 1.1359078884124756 || dis loss: 0.7515783309936523 || mse: 0.014627455733716488 | ssim:0.808863639831543\n","Epoch: 1 || Batch: 45 || unet loss: 1.290449619293213 || dis loss: 0.7746704816818237 || mse: 0.015310600399971008 | ssim:0.8456364870071411\n","Epoch: 1 || Batch: 46 || unet loss: 1.2378978729248047 || dis loss: 0.7771550416946411 || mse: 0.015166198834776878 | ssim:0.8054658770561218\n","Epoch: 1 || Batch: 47 || unet loss: 1.3176506757736206 || dis loss: 0.7961296439170837 || mse: 0.012382909655570984 | ssim:0.8356983661651611\n","Epoch: 1 || Batch: 48 || unet loss: 1.2329292297363281 || dis loss: 0.792827844619751 || mse: 0.011115264147520065 | ssim:0.8501790761947632\n","Epoch: 1 || Batch: 49 || unet loss: 1.0665180683135986 || dis loss: 0.79682457447052 || mse: 0.005297758616507053 | ssim:0.8977758288383484\n","Epoch: 1 || Batch: 50 || unet loss: 1.2392637729644775 || dis loss: 0.7968239188194275 || mse: 0.009003965184092522 | ssim:0.8467554450035095\n","Epoch: 1 || Batch: 51 || unet loss: 1.2682092189788818 || dis loss: 0.721195638179779 || mse: 0.022571958601474762 | ssim:0.7535898685455322\n","Epoch: 1 || Batch: 52 || unet loss: 1.0291295051574707 || dis loss: 0.7643818259239197 || mse: 0.00899910181760788 | ssim:0.855643630027771\n","Epoch: 1 || Batch: 53 || unet loss: 1.1377902030944824 || dis loss: 0.7558991312980652 || mse: 0.010337545536458492 | ssim:0.8660394549369812\n","Epoch: 1 || Batch: 54 || unet loss: 1.129298448562622 || dis loss: 0.7395961284637451 || mse: 0.013572104275226593 | ssim:0.8197706937789917\n","Epoch: 1 || Batch: 55 || unet loss: 1.1841328144073486 || dis loss: 0.7560096979141235 || mse: 0.009571625851094723 | ssim:0.816459596157074\n","Epoch: 1 || Batch: 56 || unet loss: 1.2185134887695312 || dis loss: 0.7842945456504822 || mse: 0.009117702022194862 | ssim:0.8505368232727051\n","Epoch: 1 || Batch: 57 || unet loss: 1.0889708995819092 || dis loss: 0.7980192303657532 || mse: 0.00839945673942566 | ssim:0.8541030883789062\n","Epoch: 1 || Batch: 58 || unet loss: 1.1833746433258057 || dis loss: 0.8176153302192688 || mse: 0.010742239654064178 | ssim:0.8544007539749146\n","Epoch: 1 || Batch: 59 || unet loss: 1.2256262302398682 || dis loss: 0.8094472289085388 || mse: 0.0150785893201828 | ssim:0.8275359869003296\n","Epoch: 1 || Batch: 60 || unet loss: 1.3982808589935303 || dis loss: 0.8112794756889343 || mse: 0.008177834562957287 | ssim:0.841587245464325\n","Epoch: 1 || Batch: 61 || unet loss: 1.028242826461792 || dis loss: 0.7925592660903931 || mse: 0.008395735174417496 | ssim:0.8895308375358582\n","Epoch: 1 || Batch: 62 || unet loss: 1.1019716262817383 || dis loss: 0.7841721177101135 || mse: 0.00741580268368125 | ssim:0.8725532293319702\n","Epoch: 1 || Batch: 63 || unet loss: 1.251794457435608 || dis loss: 0.7740789651870728 || mse: 0.00942937657237053 | ssim:0.8006231188774109\n","Epoch: 1 || Batch: 64 || unet loss: 1.1544418334960938 || dis loss: 0.8023930788040161 || mse: 0.012408698908984661 | ssim:0.8744169473648071\n","Epoch: 1 || Batch: 65 || unet loss: 1.0375571250915527 || dis loss: 0.7995330095291138 || mse: 0.006527747958898544 | ssim:0.8833823204040527\n","Epoch: 1 || Batch: 66 || unet loss: 1.0590769052505493 || dis loss: 0.8411798477172852 || mse: 0.012884191237390041 | ssim:0.8526298999786377\n","Epoch: 1 || Batch: 67 || unet loss: 1.217178225517273 || dis loss: 0.7277685403823853 || mse: 0.021715063601732254 | ssim:0.7215241193771362\n","Epoch: 1 || Batch: 68 || unet loss: 1.212341070175171 || dis loss: 0.7103476524353027 || mse: 0.024518465623259544 | ssim:0.7622183561325073\n","Epoch: 1 || Batch: 69 || unet loss: 1.0541640520095825 || dis loss: 0.7685491442680359 || mse: 0.00545991538092494 | ssim:0.8806800842285156\n","Epoch: 1 || Batch: 70 || unet loss: 1.1797053813934326 || dis loss: 0.7588760852813721 || mse: 0.01058792881667614 | ssim:0.8621987104415894\n","Epoch: 1 || Batch: 71 || unet loss: 1.2254457473754883 || dis loss: 0.7935303449630737 || mse: 0.012039314024150372 | ssim:0.8238430023193359\n","Epoch: 1 || Batch: 72 || unet loss: 1.3499263525009155 || dis loss: 0.7604324817657471 || mse: 0.0174570195376873 | ssim:0.7863141298294067\n","Epoch: 1 || Batch: 73 || unet loss: 1.1724379062652588 || dis loss: 0.8196451663970947 || mse: 0.008669997565448284 | ssim:0.8588685393333435\n","Epoch: 1 || Batch: 74 || unet loss: 0.9893482327461243 || dis loss: 0.8024036884307861 || mse: 0.004295900464057922 | ssim:0.9076392650604248\n","Epoch: 1 || Batch: 75 || unet loss: 1.1474814414978027 || dis loss: 0.7834244966506958 || mse: 0.009176947176456451 | ssim:0.8322223424911499\n","Epoch: 1 || Batch: 76 || unet loss: 1.230326533317566 || dis loss: 0.7386610507965088 || mse: 0.012590475380420685 | ssim:0.7966133952140808\n","Epoch: 1 || Batch: 77 || unet loss: 0.9281197190284729 || dis loss: 0.7705442905426025 || mse: 0.004856411833316088 | ssim:0.9048256874084473\n","Epoch: 1 || Batch: 78 || unet loss: 1.1485000848770142 || dis loss: 0.7312366962432861 || mse: 0.01707664132118225 | ssim:0.8043125867843628\n","Epoch: 1 || Batch: 79 || unet loss: 1.1119356155395508 || dis loss: 0.725437581539154 || mse: 0.015008932910859585 | ssim:0.81606525182724\n","Epoch: 1 || Batch: 80 || unet loss: 1.0648059844970703 || dis loss: 0.7619113922119141 || mse: 0.005656059365719557 | ssim:0.8602830767631531\n","Epoch: 1 || Batch: 81 || unet loss: 1.1439670324325562 || dis loss: 0.7627246379852295 || mse: 0.013235850259661674 | ssim:0.8389443755149841\n","Epoch: 1 || Batch: 82 || unet loss: 1.0054616928100586 || dis loss: 0.79290771484375 || mse: 0.006580899469554424 | ssim:0.8966531753540039\n","Epoch: 1 || Batch: 83 || unet loss: 1.1715666055679321 || dis loss: 0.8330905437469482 || mse: 0.01173761673271656 | ssim:0.8621756434440613\n","Epoch: 1 || Batch: 84 || unet loss: 1.26108980178833 || dis loss: 0.7722699642181396 || mse: 0.022007867693901062 | ssim:0.7619484663009644\n","Epoch: 1 || Batch: 85 || unet loss: 1.3457696437835693 || dis loss: 0.8139986991882324 || mse: 0.012011043727397919 | ssim:0.8329500555992126\n","Epoch: 1 || Batch: 86 || unet loss: 1.0030226707458496 || dis loss: 0.8034948110580444 || mse: 0.007019425742328167 | ssim:0.8969084620475769\n","Epoch: 1 || Batch: 87 || unet loss: 1.0387816429138184 || dis loss: 0.7820013761520386 || mse: 0.005959251429885626 | ssim:0.8930788040161133\n","Epoch: 1 || Batch: 88 || unet loss: 1.226440668106079 || dis loss: 0.7428777813911438 || mse: 0.014968822710216045 | ssim:0.7679363489151001\n","Epoch: 1 || Batch: 89 || unet loss: 1.0489897727966309 || dis loss: 0.7493453025817871 || mse: 0.012146279215812683 | ssim:0.8280972838401794\n","Epoch: 1 || Batch: 90 || unet loss: 0.9495279788970947 || dis loss: 0.7905446290969849 || mse: 0.0039587477222085 | ssim:0.9003065824508667\n","Epoch: 1 || Batch: 91 || unet loss: 1.0718401670455933 || dis loss: 0.7887866497039795 || mse: 0.01156626082956791 | ssim:0.8435620069503784\n","Epoch: 1 || Batch: 92 || unet loss: 1.2529736757278442 || dis loss: 0.7914478182792664 || mse: 0.006569174584001303 | ssim:0.8445605039596558\n","Epoch: 1 || Batch: 93 || unet loss: 1.1440191268920898 || dis loss: 0.7145130038261414 || mse: 0.020521700382232666 | ssim:0.7575041651725769\n","Epoch: 1 || Batch: 94 || unet loss: 1.0626060962677002 || dis loss: 0.783252477645874 || mse: 0.00726510351523757 | ssim:0.8788503408432007\n","Epoch: 1 || Batch: 95 || unet loss: 1.2385258674621582 || dis loss: 0.7819584608078003 || mse: 0.01573040336370468 | ssim:0.856518030166626\n","Epoch: 1 || Batch: 96 || unet loss: 1.2711639404296875 || dis loss: 0.8090612888336182 || mse: 0.011378406547009945 | ssim:0.8435959815979004\n","Epoch: 1 || Batch: 97 || unet loss: 1.3204543590545654 || dis loss: 0.7984720468521118 || mse: 0.01418051403015852 | ssim:0.8341659307479858\n","Epoch: 1 || Batch: 98 || unet loss: 1.1693276166915894 || dis loss: 0.8215780854225159 || mse: 0.008083706721663475 | ssim:0.8685275316238403\n","Epoch: 1 || Batch: 99 || unet loss: 0.9524294137954712 || dis loss: 0.7767664194107056 || mse: 0.007650039158761501 | ssim:0.862972617149353\n","Epoch: 1 || Batch: 100 || unet loss: 1.1474125385284424 || dis loss: 0.7585739493370056 || mse: 0.009614779613912106 | ssim:0.8131272196769714\n","Epoch: 1 || Batch: 101 || unet loss: 1.1851356029510498 || dis loss: 0.6896920204162598 || mse: 0.02614281140267849 | ssim:0.7627226710319519\n","Epoch: 1 || Batch: 102 || unet loss: 0.9026983976364136 || dis loss: 0.7725234627723694 || mse: 0.0027315891347825527 | ssim:0.9156286120414734\n","Epoch: 1 || Batch: 103 || unet loss: 1.1203252077102661 || dis loss: 0.7329151034355164 || mse: 0.01206643134355545 | ssim:0.8434213399887085\n","Epoch: 1 || Batch: 104 || unet loss: 1.1097774505615234 || dis loss: 0.7739325165748596 || mse: 0.008167967200279236 | ssim:0.8710659742355347\n","Epoch: 1 || Batch: 105 || unet loss: 1.1175339221954346 || dis loss: 0.7011004686355591 || mse: 0.011593545787036419 | ssim:0.7957481145858765\n","\n","mse: + 0.016347408646120214 | ssim: 0.7872641109070688 | unet:1.3413698392094306\n","\n","Epoch: 2 || Batch: 1 || unet loss: 1.2554258108139038 || dis loss: 0.7007265090942383 || mse: 0.013803891837596893 | ssim:0.7777128219604492\n","Epoch: 2 || Batch: 2 || unet loss: 0.7513248920440674 || dis loss: 0.8050145506858826 || mse: 0.00238597858697176 | ssim:0.9347138404846191\n","Epoch: 2 || Batch: 3 || unet loss: 1.0254294872283936 || dis loss: 0.7889346480369568 || mse: 0.0071701109409332275 | ssim:0.8893415927886963\n","Epoch: 2 || Batch: 4 || unet loss: 1.003706693649292 || dis loss: 0.7479636669158936 || mse: 0.010369314812123775 | ssim:0.8306729793548584\n","Epoch: 2 || Batch: 5 || unet loss: 1.0942420959472656 || dis loss: 0.7438979744911194 || mse: 0.007727421820163727 | ssim:0.8103084564208984\n","Epoch: 2 || Batch: 6 || unet loss: 1.0834938287734985 || dis loss: 0.7311516404151917 || mse: 0.010370119474828243 | ssim:0.8211950063705444\n","Epoch: 2 || Batch: 7 || unet loss: 1.0366852283477783 || dis loss: 0.7452952861785889 || mse: 0.007873493246734142 | ssim:0.8927537798881531\n","Epoch: 2 || Batch: 8 || unet loss: 1.231869101524353 || dis loss: 0.7431775331497192 || mse: 0.006354746874421835 | ssim:0.826492965221405\n","Epoch: 2 || Batch: 9 || unet loss: 1.2355327606201172 || dis loss: 0.7495509386062622 || mse: 0.01463456079363823 | ssim:0.7844063639640808\n","Epoch: 2 || Batch: 10 || unet loss: 1.2937451601028442 || dis loss: 0.7887591123580933 || mse: 0.010148199275135994 | ssim:0.8468236923217773\n","Epoch: 2 || Batch: 11 || unet loss: 0.9781734943389893 || dis loss: 0.8007249236106873 || mse: 0.007293654605746269 | ssim:0.8903385996818542\n","Epoch: 2 || Batch: 12 || unet loss: 0.9778257608413696 || dis loss: 0.8074082136154175 || mse: 0.005269161891192198 | ssim:0.8767621517181396\n","Epoch: 2 || Batch: 13 || unet loss: 1.1991990804672241 || dis loss: 0.759344220161438 || mse: 0.008557861670851707 | ssim:0.8453385233879089\n","Epoch: 2 || Batch: 14 || unet loss: 1.0491632223129272 || dis loss: 0.7949867248535156 || mse: 0.02468441240489483 | ssim:0.7969164848327637\n","Epoch: 2 || Batch: 15 || unet loss: 1.1396323442459106 || dis loss: 0.7603210210800171 || mse: 0.014606157317757607 | ssim:0.7944504618644714\n","Epoch: 2 || Batch: 16 || unet loss: 1.066740870475769 || dis loss: 0.775718092918396 || mse: 0.011570502072572708 | ssim:0.8242813348770142\n","Epoch: 2 || Batch: 17 || unet loss: 1.1097394227981567 || dis loss: 0.7691798210144043 || mse: 0.0119877178221941 | ssim:0.7943848967552185\n","Epoch: 2 || Batch: 18 || unet loss: 1.0175074338912964 || dis loss: 0.7955498695373535 || mse: 0.007833423092961311 | ssim:0.8623896837234497\n","Epoch: 2 || Batch: 19 || unet loss: 0.9638381004333496 || dis loss: 0.8053090572357178 || mse: 0.0059613874182105064 | ssim:0.8889908790588379\n","Epoch: 2 || Batch: 20 || unet loss: 1.0583938360214233 || dis loss: 0.7985444068908691 || mse: 0.004902341403067112 | ssim:0.8902511596679688\n","Epoch: 2 || Batch: 21 || unet loss: 1.2353272438049316 || dis loss: 0.7812672853469849 || mse: 0.006132244132459164 | ssim:0.8458146452903748\n","Epoch: 2 || Batch: 22 || unet loss: 1.160745620727539 || dis loss: 0.779149055480957 || mse: 0.00984023418277502 | ssim:0.8445190191268921\n","Epoch: 2 || Batch: 23 || unet loss: 1.0991992950439453 || dis loss: 0.7652231454849243 || mse: 0.007229174487292767 | ssim:0.8828364610671997\n","Epoch: 2 || Batch: 24 || unet loss: 0.8982755541801453 || dis loss: 0.7735822200775146 || mse: 0.003812521230429411 | ssim:0.8972777128219604\n","Epoch: 2 || Batch: 25 || unet loss: 1.1091896295547485 || dis loss: 0.7937092781066895 || mse: 0.007942253723740578 | ssim:0.8386707305908203\n","Epoch: 2 || Batch: 26 || unet loss: 1.1252161264419556 || dis loss: 0.7971574664115906 || mse: 0.008093922398984432 | ssim:0.8664214015007019\n","Epoch: 2 || Batch: 27 || unet loss: 0.8979992270469666 || dis loss: 0.8080489039421082 || mse: 0.007877524010837078 | ssim:0.8577444553375244\n","Epoch: 2 || Batch: 28 || unet loss: 1.0008392333984375 || dis loss: 0.805834174156189 || mse: 0.007889371365308762 | ssim:0.8933244943618774\n","Epoch: 2 || Batch: 29 || unet loss: 1.0508649349212646 || dis loss: 0.7141155004501343 || mse: 0.01694628596305847 | ssim:0.802212119102478\n","Epoch: 2 || Batch: 30 || unet loss: 1.1302241086959839 || dis loss: 0.603879451751709 || mse: 0.02114281617105007 | ssim:0.7094517946243286\n","Epoch: 2 || Batch: 31 || unet loss: 1.0539089441299438 || dis loss: 0.7488798499107361 || mse: 0.009781304746866226 | ssim:0.842005729675293\n","Epoch: 2 || Batch: 32 || unet loss: 1.1037521362304688 || dis loss: 0.7353838086128235 || mse: 0.011533796787261963 | ssim:0.840406596660614\n","Epoch: 2 || Batch: 33 || unet loss: 1.29429292678833 || dis loss: 0.7971706390380859 || mse: 0.010696006938815117 | ssim:0.8475944995880127\n","Epoch: 2 || Batch: 34 || unet loss: 1.122706651687622 || dis loss: 0.7773648500442505 || mse: 0.016231367364525795 | ssim:0.8205839991569519\n","Epoch: 2 || Batch: 35 || unet loss: 1.4189977645874023 || dis loss: 0.8066829442977905 || mse: 0.009077945724129677 | ssim:0.8430272936820984\n","Epoch: 2 || Batch: 36 || unet loss: 0.934099555015564 || dis loss: 0.8065404295921326 || mse: 0.005692715756595135 | ssim:0.9093734622001648\n","Epoch: 2 || Batch: 37 || unet loss: 0.9063653349876404 || dis loss: 0.8205870389938354 || mse: 0.0065869782119989395 | ssim:0.865534245967865\n","Epoch: 2 || Batch: 38 || unet loss: 1.1028318405151367 || dis loss: 0.7624700665473938 || mse: 0.013021865859627724 | ssim:0.771160364151001\n","Epoch: 2 || Batch: 39 || unet loss: 1.0426123142242432 || dis loss: 0.769692063331604 || mse: 0.008460259065032005 | ssim:0.8933545351028442\n","Epoch: 2 || Batch: 40 || unet loss: 1.046128273010254 || dis loss: 0.7536277174949646 || mse: 0.005532215815037489 | ssim:0.8825880885124207\n","Epoch: 2 || Batch: 41 || unet loss: 1.0885440111160278 || dis loss: 0.7423297166824341 || mse: 0.013549658469855785 | ssim:0.8168784976005554\n","Epoch: 2 || Batch: 42 || unet loss: 1.1508427858352661 || dis loss: 0.7051558494567871 || mse: 0.012341713532805443 | ssim:0.751893162727356\n","Epoch: 2 || Batch: 43 || unet loss: 1.1267285346984863 || dis loss: 0.7065715193748474 || mse: 0.01850314997136593 | ssim:0.7826535105705261\n","Epoch: 2 || Batch: 44 || unet loss: 0.9094526767730713 || dis loss: 0.7760759592056274 || mse: 0.004482249729335308 | ssim:0.8976535201072693\n","Epoch: 2 || Batch: 45 || unet loss: 0.9643912315368652 || dis loss: 0.7802372574806213 || mse: 0.006618012674152851 | ssim:0.8954682350158691\n","Epoch: 2 || Batch: 46 || unet loss: 1.1609798669815063 || dis loss: 0.8037509322166443 || mse: 0.007883928716182709 | ssim:0.8413909673690796\n","Epoch: 2 || Batch: 47 || unet loss: 1.211466670036316 || dis loss: 0.7397862672805786 || mse: 0.016079409047961235 | ssim:0.792041540145874\n","Epoch: 2 || Batch: 48 || unet loss: 1.1053800582885742 || dis loss: 0.772357702255249 || mse: 0.006907667964696884 | ssim:0.8578423261642456\n","Epoch: 2 || Batch: 49 || unet loss: 0.8256632089614868 || dis loss: 0.7476690411567688 || mse: 0.003576507791876793 | ssim:0.9052552580833435\n","Epoch: 2 || Batch: 50 || unet loss: 1.1236175298690796 || dis loss: 0.7549326419830322 || mse: 0.006798088550567627 | ssim:0.8665280342102051\n","Epoch: 2 || Batch: 51 || unet loss: 1.1361274719238281 || dis loss: 0.6983231902122498 || mse: 0.010606403462588787 | ssim:0.7803249359130859\n","Epoch: 2 || Batch: 52 || unet loss: 0.9251422882080078 || dis loss: 0.7041544318199158 || mse: 0.009581206366419792 | ssim:0.8514492511749268\n","Epoch: 2 || Batch: 53 || unet loss: 1.03165602684021 || dis loss: 0.7603275775909424 || mse: 0.008753718808293343 | ssim:0.8835406303405762\n","Epoch: 2 || Batch: 54 || unet loss: 1.0824599266052246 || dis loss: 0.805566132068634 || mse: 0.008657362312078476 | ssim:0.8738457560539246\n","Epoch: 2 || Batch: 55 || unet loss: 0.9429183602333069 || dis loss: 0.7745514512062073 || mse: 0.006608731113374233 | ssim:0.8333615064620972\n","Epoch: 2 || Batch: 56 || unet loss: 1.0320323705673218 || dis loss: 0.7634133696556091 || mse: 0.008097341284155846 | ssim:0.8899845480918884\n","Epoch: 2 || Batch: 57 || unet loss: 1.0829051733016968 || dis loss: 0.7840110659599304 || mse: 0.01598512753844261 | ssim:0.8691000938415527\n","Epoch: 2 || Batch: 58 || unet loss: 1.2506694793701172 || dis loss: 0.8427623510360718 || mse: 0.011155720800161362 | ssim:0.8426856994628906\n","Epoch: 2 || Batch: 59 || unet loss: 1.0755060911178589 || dis loss: 0.8313788175582886 || mse: 0.0096033476293087 | ssim:0.8698980212211609\n","Epoch: 2 || Batch: 60 || unet loss: 1.269420862197876 || dis loss: 0.8194270133972168 || mse: 0.008624933660030365 | ssim:0.8572988510131836\n","Epoch: 2 || Batch: 61 || unet loss: 0.9260112643241882 || dis loss: 0.8259024620056152 || mse: 0.005011996254324913 | ssim:0.9092000722885132\n","Epoch: 2 || Batch: 62 || unet loss: 0.9929297566413879 || dis loss: 0.7767016887664795 || mse: 0.009677441790699959 | ssim:0.8084027767181396\n","Epoch: 2 || Batch: 63 || unet loss: 1.174338936805725 || dis loss: 0.748898983001709 || mse: 0.01106120552867651 | ssim:0.7912194132804871\n","Epoch: 2 || Batch: 64 || unet loss: 1.0921599864959717 || dis loss: 0.7028460502624512 || mse: 0.021641090512275696 | ssim:0.7914645671844482\n","Epoch: 2 || Batch: 65 || unet loss: 1.019282341003418 || dis loss: 0.7619855999946594 || mse: 0.005266969557851553 | ssim:0.8817343711853027\n","Epoch: 2 || Batch: 66 || unet loss: 0.9261581897735596 || dis loss: 0.7930096387863159 || mse: 0.008416635915637016 | ssim:0.9021369814872742\n","Epoch: 2 || Batch: 67 || unet loss: 1.1643731594085693 || dis loss: 0.7731198072433472 || mse: 0.009077589027583599 | ssim:0.7956085205078125\n","Epoch: 2 || Batch: 68 || unet loss: 0.9469001889228821 || dis loss: 0.7867876887321472 || mse: 0.006487593054771423 | ssim:0.9060651659965515\n","Epoch: 2 || Batch: 69 || unet loss: 0.8899911642074585 || dis loss: 0.8166242241859436 || mse: 0.00623471662402153 | ssim:0.9011412858963013\n","Epoch: 2 || Batch: 70 || unet loss: 1.0860483646392822 || dis loss: 0.7975980043411255 || mse: 0.01154364924877882 | ssim:0.8761156797409058\n","Epoch: 2 || Batch: 71 || unet loss: 1.2023537158966064 || dis loss: 0.8078723549842834 || mse: 0.00988522544503212 | ssim:0.8559941053390503\n","Epoch: 2 || Batch: 72 || unet loss: 1.1079177856445312 || dis loss: 0.7891882658004761 || mse: 0.008583491668105125 | ssim:0.8809379935264587\n","Epoch: 2 || Batch: 73 || unet loss: 1.0993648767471313 || dis loss: 0.7929891347885132 || mse: 0.007027539424598217 | ssim:0.8834719061851501\n","Epoch: 2 || Batch: 74 || unet loss: 0.8285691738128662 || dis loss: 0.7837821841239929 || mse: 0.0032965396530926228 | ssim:0.9395119547843933\n","Epoch: 2 || Batch: 75 || unet loss: 1.0792629718780518 || dis loss: 0.7660962343215942 || mse: 0.008223805576562881 | ssim:0.8289602994918823\n","Epoch: 2 || Batch: 76 || unet loss: 1.1113111972808838 || dis loss: 0.7070829272270203 || mse: 0.022018447518348694 | ssim:0.7791966199874878\n","Epoch: 2 || Batch: 77 || unet loss: 0.9351586103439331 || dis loss: 0.7492783069610596 || mse: 0.005964898504316807 | ssim:0.8649333715438843\n","Epoch: 2 || Batch: 78 || unet loss: 0.9794236421585083 || dis loss: 0.7659338712692261 || mse: 0.008169790729880333 | ssim:0.8958298563957214\n","Epoch: 2 || Batch: 79 || unet loss: 1.037481427192688 || dis loss: 0.7469930648803711 || mse: 0.007678610272705555 | ssim:0.8647621870040894\n","Epoch: 2 || Batch: 80 || unet loss: 1.0991846323013306 || dis loss: 0.676668643951416 || mse: 0.010856392793357372 | ssim:0.7780263423919678\n","Epoch: 2 || Batch: 81 || unet loss: 1.0154706239700317 || dis loss: 0.7398950457572937 || mse: 0.009189087897539139 | ssim:0.8547255396842957\n","Epoch: 2 || Batch: 82 || unet loss: 0.92378830909729 || dis loss: 0.7756549715995789 || mse: 0.005769800394773483 | ssim:0.9068486094474792\n","Epoch: 2 || Batch: 83 || unet loss: 1.1859080791473389 || dis loss: 0.8006526827812195 || mse: 0.006909200455993414 | ssim:0.8705024719238281\n","Epoch: 2 || Batch: 84 || unet loss: 1.0406064987182617 || dis loss: 0.8256691694259644 || mse: 0.012097014114260674 | ssim:0.8496732711791992\n","Epoch: 2 || Batch: 85 || unet loss: 1.3095704317092896 || dis loss: 0.8037329912185669 || mse: 0.0071975491009652615 | ssim:0.857154369354248\n","Epoch: 2 || Batch: 86 || unet loss: 0.8847075700759888 || dis loss: 0.8037941455841064 || mse: 0.005592898465692997 | ssim:0.9127950072288513\n","Epoch: 2 || Batch: 87 || unet loss: 0.9172148108482361 || dis loss: 0.803850531578064 || mse: 0.004820005036890507 | ssim:0.9110857844352722\n","Epoch: 2 || Batch: 88 || unet loss: 1.0639110803604126 || dis loss: 0.8159913420677185 || mse: 0.00540985306724906 | ssim:0.8547115325927734\n","Epoch: 2 || Batch: 89 || unet loss: 0.950971245765686 || dis loss: 0.7432670593261719 || mse: 0.007987616583704948 | ssim:0.8469115495681763\n","Epoch: 2 || Batch: 90 || unet loss: 0.9812698364257812 || dis loss: 0.7822299003601074 || mse: 0.004780706018209457 | ssim:0.8865498900413513\n","Epoch: 2 || Batch: 91 || unet loss: 0.9858774542808533 || dis loss: 0.7727246880531311 || mse: 0.009287424385547638 | ssim:0.867741048336029\n","Epoch: 2 || Batch: 92 || unet loss: 1.1327111721038818 || dis loss: 0.7070184946060181 || mse: 0.009221162647008896 | ssim:0.781890869140625\n","Epoch: 2 || Batch: 93 || unet loss: 1.0238804817199707 || dis loss: 0.720382809638977 || mse: 0.00799246970564127 | ssim:0.8537559509277344\n","Epoch: 2 || Batch: 94 || unet loss: 0.9369041323661804 || dis loss: 0.7470623254776001 || mse: 0.007301207631826401 | ssim:0.864951491355896\n","Epoch: 2 || Batch: 95 || unet loss: 1.040401577949524 || dis loss: 0.7521778345108032 || mse: 0.013969700783491135 | ssim:0.8781770467758179\n","Epoch: 2 || Batch: 96 || unet loss: 1.2744057178497314 || dis loss: 0.7965357303619385 || mse: 0.01066138781607151 | ssim:0.8412872552871704\n","Epoch: 2 || Batch: 97 || unet loss: 1.1471446752548218 || dis loss: 0.813164472579956 || mse: 0.011129598133265972 | ssim:0.869225263595581\n","Epoch: 2 || Batch: 98 || unet loss: 1.0726652145385742 || dis loss: 0.7993269562721252 || mse: 0.006662639789283276 | ssim:0.8835339546203613\n","Epoch: 2 || Batch: 99 || unet loss: 0.7536001801490784 || dis loss: 0.7833428382873535 || mse: 0.0027117165736854076 | ssim:0.9455992579460144\n","Epoch: 2 || Batch: 100 || unet loss: 1.0588617324829102 || dis loss: 0.772878110408783 || mse: 0.005543798208236694 | ssim:0.8569598197937012\n","Epoch: 2 || Batch: 101 || unet loss: 1.1195170879364014 || dis loss: 0.6821082234382629 || mse: 0.013018762692809105 | ssim:0.7591137290000916\n","Epoch: 2 || Batch: 102 || unet loss: 0.9935600161552429 || dis loss: 0.6928446292877197 || mse: 0.015378715470433235 | ssim:0.8142317533493042\n","Epoch: 2 || Batch: 103 || unet loss: 1.1038470268249512 || dis loss: 0.7038586139678955 || mse: 0.008942322805523872 | ssim:0.8367010354995728\n","Epoch: 2 || Batch: 104 || unet loss: 1.0493699312210083 || dis loss: 0.7557218074798584 || mse: 0.007196564227342606 | ssim:0.8917759656906128\n","Epoch: 2 || Batch: 105 || unet loss: 0.9758042693138123 || dis loss: 0.7401019334793091 || mse: 0.006372235249727964 | ssim:0.8656457662582397\n","\n","mse: + 0.009176477425257271 | ssim: 0.8442243714377565 | unet:1.0513334010007247\n","\n","Epoch: 3 || Batch: 1 || unet loss: 1.0761686563491821 || dis loss: 0.7207661271095276 || mse: 0.015057126991450787 | ssim:0.7830225229263306\n","Epoch: 3 || Batch: 2 || unet loss: 0.8352275490760803 || dis loss: 0.7760922312736511 || mse: 0.00659130048006773 | ssim:0.8749641180038452\n","Epoch: 3 || Batch: 3 || unet loss: 0.9784129858016968 || dis loss: 0.7877731323242188 || mse: 0.008702348917722702 | ssim:0.8850444555282593\n","Epoch: 3 || Batch: 4 || unet loss: 0.9598875045776367 || dis loss: 0.7317951917648315 || mse: 0.010585581883788109 | ssim:0.8424438834190369\n","Epoch: 3 || Batch: 5 || unet loss: 0.995120644569397 || dis loss: 0.8149561882019043 || mse: 0.005155171267688274 | ssim:0.8584663271903992\n","Epoch: 3 || Batch: 6 || unet loss: 1.0408878326416016 || dis loss: 0.7292132377624512 || mse: 0.00983341783285141 | ssim:0.8453631401062012\n","Epoch: 3 || Batch: 7 || unet loss: 0.9694940447807312 || dis loss: 0.7803394198417664 || mse: 0.006493018474429846 | ssim:0.8821061849594116\n","Epoch: 3 || Batch: 8 || unet loss: 1.1749612092971802 || dis loss: 0.769165575504303 || mse: 0.00681218272075057 | ssim:0.8697981834411621\n","Epoch: 3 || Batch: 9 || unet loss: 1.2252141237258911 || dis loss: 0.8202903270721436 || mse: 0.01111618336290121 | ssim:0.8270565867424011\n","Epoch: 3 || Batch: 10 || unet loss: 1.1804291009902954 || dis loss: 0.8140144944190979 || mse: 0.006437239237129688 | ssim:0.8718995451927185\n","Epoch: 3 || Batch: 11 || unet loss: 0.7993203997612 || dis loss: 0.8263932466506958 || mse: 0.004621510393917561 | ssim:0.9135093688964844\n","Epoch: 3 || Batch: 12 || unet loss: 0.9635500311851501 || dis loss: 0.7987913489341736 || mse: 0.011785763315856457 | ssim:0.8088619112968445\n","Epoch: 3 || Batch: 13 || unet loss: 1.0749186277389526 || dis loss: 0.7978221774101257 || mse: 0.005175359081476927 | ssim:0.8389166593551636\n","Epoch: 3 || Batch: 14 || unet loss: 0.9982902407646179 || dis loss: 0.7667542099952698 || mse: 0.008455263450741768 | ssim:0.8731034994125366\n","Epoch: 3 || Batch: 15 || unet loss: 0.9417909383773804 || dis loss: 0.7549675107002258 || mse: 0.003311608452349901 | ssim:0.911973237991333\n","Epoch: 3 || Batch: 16 || unet loss: 0.9289480447769165 || dis loss: 0.7772039175033569 || mse: 0.006171821616590023 | ssim:0.911313533782959\n","Epoch: 3 || Batch: 17 || unet loss: 1.1698832511901855 || dis loss: 0.7636576890945435 || mse: 0.007668042089790106 | ssim:0.7907928824424744\n","Epoch: 3 || Batch: 18 || unet loss: 0.8993057608604431 || dis loss: 0.7791382670402527 || mse: 0.00774878915399313 | ssim:0.9058427214622498\n","Epoch: 3 || Batch: 19 || unet loss: 0.888827919960022 || dis loss: 0.7996246814727783 || mse: 0.007215758319944143 | ssim:0.8779118061065674\n","loading error: O-Haze/train/haze/40_outdoor_hazy.jpg\n","Epoch: 3 || Batch: 20 || unet loss: 0.9032717347145081 || dis loss: 0.7846924066543579 || mse: 0.009374848566949368 | ssim:0.8978567123413086\n","Epoch: 3 || Batch: 21 || unet loss: 1.2256247997283936 || dis loss: 0.8123809099197388 || mse: 0.007298992481082678 | ssim:0.8456053733825684\n","Epoch: 3 || Batch: 22 || unet loss: 1.1168701648712158 || dis loss: 0.8088369369506836 || mse: 0.011531397700309753 | ssim:0.8682600855827332\n","Epoch: 3 || Batch: 23 || unet loss: 1.1559269428253174 || dis loss: 0.7870301008224487 || mse: 0.005101009272038937 | ssim:0.8732178211212158\n","Epoch: 3 || Batch: 24 || unet loss: 0.7842261791229248 || dis loss: 0.7745368480682373 || mse: 0.0022856942377984524 | ssim:0.9443585276603699\n","Epoch: 3 || Batch: 25 || unet loss: 1.0384191274642944 || dis loss: 0.7760765552520752 || mse: 0.005887204315513372 | ssim:0.8708888292312622\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_40974/454015706.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_40974/162521350.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(max_epochs, current_epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0munet_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhaze_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdehaze_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0munet_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDUNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhaze_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdehaze_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mDUNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m' || Batch: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m\" || unet loss: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" || dis loss: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" || mse: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" | ssim:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_40974/2513380627.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, haze_images, dehaze_images)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mdis_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhaze_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# unet loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/bpp_net/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/bpp_net/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/bpp_net/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/bpp_net/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/bpp_net/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/bpp_net/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["epochs = 50\n","torch.autograd.set_detect_anomaly(True)\n","train(epochs)"]},{"cell_type":"markdown","metadata":{"id":"3vXFZE36R-C_"},"source":["Saving weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZKT5tEJmAABT"},"outputs":[],"source":["path_of_generator_weight = 'weight/generator.pth'  #path for storing the weights of genertaor\n","path_of_discriminator_weight = 'weight/discriminator.pth'  #path for storing the weights of discriminator\n","DUNet.save_weight(path_of_generator_weight,path_of_discriminator_weight)"]},{"cell_type":"markdown","metadata":{"id":"AWqkb8epSIup"},"source":["Saving weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aPjwtGKeAABV"},"outputs":[],"source":["path_of_generator_weight = 'weight/hj_train_211201_lr0.001_generator_0.pth'  #path where the weights of genertaor are stored\n","path_of_discriminator_weight = 'weight/hj_train_20211201_lr0.001_discriminator_0.pth'  #path where the weights of discriminator are stored\n","DUNet.load(path_of_generator_weight, path_of_discriminator_weight)"]},{"cell_type":"markdown","metadata":{"id":"3MAztif9SRC_"},"source":["Runing the model on test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rEMIiCj3AABe"},"outputs":[],"source":["def to_tensor(img):\n","    img_t = F6.to_tensor(img).float()\n","    return img_t\n","\n","def postprocess(img):\n","        img = img * 255.0\n","        img = img.permute(0, 2, 3, 1)\n","        return img.int()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jru-qj5JH9bf"},"outputs":[],"source":["from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Bb-OyJTAABh"},"outputs":[],"source":["path_of_test_hazy_images = 'test/hazy/*.png'\n","path_for_resultant_dehaze_images = 'test/result/test_'\n","image_paths_test_hazy=glob.glob(path_of_test_hazy_images)\n","\n","for i in range(len(image_paths_test_hazy)):\n","    haze_image = cv2.imread(image_paths_test_hazy[i])\n","    haze_image = Image.fromarray(haze_image)\n","    haze_image = haze_image.resize((512,512), resample=PIL.Image.BICUBIC)\n","    haze_image = np.array(haze_image)\n","    haze_image = cv2.cvtColor(haze_image, cv2.COLOR_BGR2YCrCb)\n","    haze_image = to_tensor(haze_image).cuda()\n","    haze_image = haze_image.reshape(1,3,512,512)\n","\n","    dehaze_image = DUNet.predict(haze_image) \n","    \n","    dehaze_image = postprocess(dehaze_image)[0]\n","    dehaze_image = dehaze_image.cpu().detach().numpy()\n","    dehaze_image = dehaze_image.astype('uint8')\n","    dehaze_image = dehaze_image.reshape(512,512,3)\n","    dehaze_image = cv2.cvtColor(dehaze_image, cv2.COLOR_YCrCb2BGR)\n","    cv2.imwrite(path_for_resultant_dehaze_images+str(i+50)+'.png', dehaze_image)"]},{"cell_type":"markdown","metadata":{"id":"YcYTCrl_SZGz"},"source":["Calculating the metrices i.e PSNR and SSIM for testing data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jgJC-JMuAABl"},"outputs":[],"source":["class EdgeAccuracy(nn.Module):\n","    \"\"\"\n","    Measures the accuracy of the edge map\n","    \"\"\"\n","    def __init__(self, threshold=0.5):\n","        super().__init__()\n","        self.threshold = threshold\n","\n","    def __call__(self, inputs, outputs):\n","        labels = (inputs > self.threshold)\n","        outputs = (outputs > self.threshold)\n","\n","        relevant = torch.sum(labels.float())\n","        selected = torch.sum(outputs.float())\n","\n","        if relevant == 0 and selected == 0:\n","            return 1, 1\n","\n","        true_positive = ((outputs == labels) * labels).float()\n","        recall = torch.sum(true_positive) / (relevant + 1e-8)\n","        precision = torch.sum(true_positive) / (selected + 1e-8)\n","\n","        return precision, recall\n","\n","\n","class PSNR(nn.Module):\n","    def __init__(self, max_val=0):\n","        super().__init__()\n","\n","        base10 = torch.log(torch.tensor(10.0))\n","        max_val = torch.tensor(max_val).float()\n","\n","        self.register_buffer('base10', base10)\n","        self.register_buffer('max_val', 20 * torch.log(max_val) / base10)\n","\n","    def __call__(self, a, b):\n","        mse = torch.mean((a.float() - b.float()) ** 2)\n","    \n","        if mse == 0:\n","            return 0\n","\n","        return 1.0 / mse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fsxd9gSxAABm"},"outputs":[],"source":["def gaussian(window_size, sigma):\n","    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n","    return gauss/gauss.sum()\n","\n","def create_window(window_size, channel):\n","    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n","    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n","    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n","    return window\n","\n","def _ssim(img1, img2, window, window_size, channel, size_average = True):\n","    mu1 = F9.conv2d(img1, window, padding = window_size//2, groups = channel)\n","    mu2 = F9.conv2d(img2, window, padding = window_size//2, groups = channel)\n","\n","    mu1_sq = mu1.pow(2)\n","    mu2_sq = mu2.pow(2)\n","    mu1_mu2 = mu1*mu2\n","\n","    sigma1_sq = F9.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n","    sigma2_sq = F9.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n","    sigma12 = F9.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n","\n","    C1 = 0.01**2\n","    C2 = 0.03**2\n","\n","    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n","\n","    if size_average:\n","        return ssim_map.mean()\n","    else:\n","        return ssim_map.mean(1).mean(1).mean(1)\n","\n","class SSIM(torch.nn.Module):\n","    def __init__(self, window_size = 11, size_average = True):\n","        super(SSIM, self).__init__()\n","        self.window_size = window_size\n","        self.size_average = size_average\n","        self.channel = 1\n","        self.window = create_window(window_size, self.channel)\n","\n","    def forward(self, img1, img2):\n","        (_, channel, _, _) = img1.size()\n","\n","        if channel == self.channel and self.window.data.type() == img1.data.type():\n","            window = self.window\n","        else:\n","            window = create_window(self.window_size, channel)\n","            \n","            if img1.is_cuda:\n","                window = window.cuda(img1.get_device())\n","            window = window.type_as(img1)\n","            \n","            self.window = window\n","            self.channel = channel\n","\n","\n","        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n","\n","def ssim(img1, img2, window_size = 11, size_average = True):\n","    (_, channel, _, _) = img1.size()\n","    window = create_window(window_size, channel)\n","    \n","    if img1.is_cuda:\n","        window = window.cuda(img1.get_device())\n","    window = window.type_as(img1)\n","    \n","    return _ssim(img1, img2, window, window_size, channel, size_average)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9hTzS1wUAABq"},"outputs":[],"source":["ssim = SSIM(window_size = 11)\n","psnr = PSNR()\n","psnr_val = 0\n","psnr_val = 0.0\n","final_ssim = 0\n","\n","path_of_test_hazy_images = 'test/haze/*.png'\n","path_of_test_gt_images = 'test/gt/*.png'\n","path_for_resultant_dehaze_images = 'test/result/'\n","\n","image_paths_test_hazy=glob.glob(path_of_test_hazy_images)\n","image_paths_test_gt=glob.glob(path_of_test_gt_images)\n","\n","for i in range(len(image_paths_test_hazy)):\n","    im1 = cv2.imread(image_paths_GT[i])\n","    im1 = Image.fromarray(im1)\n","    im1 = im1.resize((512,512), resample=PIL.Image.BICUBIC)\n","    im1 = np.array(im1)\n","    im2 = cv2.imread('Results/experiment yrcrcb/new/outdoor/' + str(i+50)+'.png')\n","\n","    im1 = to_tensor(im1).reshape(1,3,512,512)\n","    im2 = to_tensor(im2).reshape(1,3,512,512)\n","    \n","    psnr_val = psnr(im1, im2)\n","    final_psnr = final_psnr + 10*np.log10((psnr_val))\n","    final_ssim = final_ssim + ssim(im1, im2)\n","\n","\n","print(final_ssim/5.0, final_psnr/5.0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WGWLUya4AAB0"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Single_Image_Dehazing.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00bd30886cab4fe682e25a897b7dde9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2182e0fd245b47c6a4b2effc75772271":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"39b1407cce964ccc80dde8685c296bb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fea42f5b82c464895c39da4c89bc001":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b67b16690dc8453faf8c4b5e3866d3db","placeholder":"​","style":"IPY_MODEL_39b1407cce964ccc80dde8685c296bb7","value":" 548M/548M [02:14&lt;00:00, 4.26MB/s]"}},"b67b16690dc8453faf8c4b5e3866d3db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d34e39b5242f4a9da3e0d1bc428b9e13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_00bd30886cab4fe682e25a897b7dde9c","max":574673361,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2182e0fd245b47c6a4b2effc75772271","value":574673361}},"ebe9a67a932540f5915ea51ec0a5270a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d34e39b5242f4a9da3e0d1bc428b9e13","IPY_MODEL_5fea42f5b82c464895c39da4c89bc001"],"layout":"IPY_MODEL_f7c88cdd25194de19710363de98990aa"}},"f7c88cdd25194de19710363de98990aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
