{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21550,"status":"ok","timestamp":1638352048478,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"tIbffa2CMy9c","outputId":"e31b2095-8716-4ca4-c52b-8bcc528ae140"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2001,"status":"ok","timestamp":1638352050475,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"askoN0AHP7SH","outputId":"75f7827c-c4ee-4f6b-94af-876221ce71e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/comp4471/project/BPPNet-Back-Projected-Pyramid-Network\n"]}],"source":["%cd /content/drive/MyDrive/comp4471/project/BPPNet-Back-Projected-Pyramid-Network"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":29719,"status":"ok","timestamp":1638352086471,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"NDk-YhRbPxSw","outputId":"1da739bf-8edf-4d71-f2be-52b3cc19896b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: asn1crypto==1.2.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 1)) (1.2.0)\n","Requirement already satisfied: certifi==2019.11.28 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 2)) (2019.11.28)\n","Requirement already satisfied: cffi==1.13.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 3)) (1.13.0)\n","Requirement already satisfied: chardet==3.0.4 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 4)) (3.0.4)\n","Requirement already satisfied: cryptography==2.8 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 7)) (2.8)\n","Requirement already satisfied: Django==2.2.5 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 8)) (2.2.5)\n","Requirement already satisfied: docopt==0.6.2 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 9)) (0.6.2)\n","Requirement already satisfied: future==0.18.2 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 10)) (0.18.2)\n","Requirement already satisfied: idna==2.8 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 11)) (2.8)\n","Requirement already satisfied: mime==0.1.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 12)) (0.1.0)\n","Collecting numpy==1.18.1\n","  Using cached numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n","Requirement already satisfied: opencv-python==4.1.2.30 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 14)) (4.1.2.30)\n","Requirement already satisfied: pipreqs==0.4.10 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 15)) (0.4.10)\n","Requirement already satisfied: pycosat==0.6.3 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 16)) (0.6.3)\n","Requirement already satisfied: pycparser==2.19 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 17)) (2.19)\n","Requirement already satisfied: PyJWT==1.7.1 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 18)) (1.7.1)\n","Requirement already satisfied: pyOpenSSL==19.0.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 19)) (19.0.0)\n","Requirement already satisfied: PySocks==1.7.1 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 20)) (1.7.1)\n","Requirement already satisfied: pytz==2019.3 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 21)) (2019.3)\n","Requirement already satisfied: requests==2.22.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 22)) (2.22.0)\n","Requirement already satisfied: ruamel-yaml==0.15.46 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 23)) (0.15.46)\n","Requirement already satisfied: six==1.12.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 24)) (1.12.0)\n","Requirement already satisfied: sqlparse==0.3.0 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 25)) (0.3.0)\n","Requirement already satisfied: tqdm==4.36.1 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 26)) (4.36.1)\n","Requirement already satisfied: twilio==6.35.2 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 27)) (6.35.2)\n","Requirement already satisfied: urllib3==1.24.2 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 28)) (1.24.2)\n","Requirement already satisfied: yarg==0.1.9 in /data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages (from -r Requirements.txt (line 29)) (0.1.9)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.2\n","    Uninstalling numpy-1.21.2:\n","      Successfully uninstalled numpy-1.21.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pyrender 0.1.45 requires freetype-py, which is not installed.\n","pyrender 0.1.45 requires pyglet>=1.4.10, which is not installed.\n","pyrender 0.1.45 requires PyOpenGL==3.1.0, which is not installed.\n","pyrender 0.1.45 requires trimesh, which is not installed.\u001b[0m\n","Successfully installed numpy-1.18.1\n"]}],"source":["!pip install -r Requirements.txt"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8015,"status":"ok","timestamp":1638352097909,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"QJPU0tPrAAAi"},"outputs":[],"source":["import os\n","import cv2\n","import PIL\n","import glob\n","import torch\n","import scipy\n","import random\n","import shutil\n","import numpy as np\n","import pandas as pd\n","from math import exp\n","import torch.nn as nn\n","from PIL import Image\n","from tqdm import tqdm\n","from scipy import ndimage\n","import torch.optim as optim\n","from sklearn import metrics\n","from torch.utils import data\n","from sklearn import datasets\n","from skimage.io import imsave\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F3\n","import torch.nn.functional as F9\n","from sklearn import linear_model\n","from skimage.feature import canny\n","from torch.autograd import Variable\n","import torchvision.models as models\n","from collections import OrderedDict\n","from torch.autograd import Variable\n","from matplotlib.pyplot import imshow\n","from matplotlib import pyplot as plt1\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import KFold\n","from IPython.display import display, Image\n","from skimage.color import lab2rgb, rgb2lab\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as F\n","import torchvision.transforms.functional as F6\n","import torchvision.transforms.functional as F7\n","from sklearn.preprocessing import OneHotEncoder \n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error,r2_score\n","from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n","from sklearn.model_selection import cross_val_score, cross_val_predict"]},{"cell_type":"markdown","metadata":{"id":"3OcaGLs7bOiE"},"source":["Defining our generator (UNet)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1368,"status":"ok","timestamp":1638352104172,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"uPQd3FlmAAAk"},"outputs":[],"source":["class UNet(nn.Module):\n","\n","    def __init__(self, in_channels=3, out_channels=3, init_features=32):\n","        super(UNet, self).__init__()\n","\n","        features = init_features\n","        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n","        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n","        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n","\n","        self.upconv4 = nn.ConvTranspose2d(\n","            features * 16, features * 8, kernel_size=2, stride=2\n","        )\n","        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n","        self.upconv3 = nn.ConvTranspose2d(\n","            features * 8, features * 4, kernel_size=2, stride=2\n","        )\n","        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n","        self.upconv2 = nn.ConvTranspose2d(\n","            features * 4, features * 2, kernel_size=2, stride=2\n","        )\n","        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n","        self.upconv1 = nn.ConvTranspose2d(\n","            features * 2, features, kernel_size=2, stride=2\n","        )\n","        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n","\n","        self.conv = nn.Conv2d(\n","            in_channels=features, out_channels=out_channels, kernel_size=1\n","        )\n","\n","        self.conv_1 = nn.Conv2d(\n","            in_channels=128, out_channels=out_channels, kernel_size=1\n","        )\n","\n","        self.pyramid_3 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=3, padding=1),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_5 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=5, padding=2),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_7 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=7, padding=3),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_11 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=11, padding=5),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_17 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=17, padding=8),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_25 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=25, padding=12),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_35 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=35, padding=17),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","        self.pyramid_45 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=45, padding=22),\n","            nn.InstanceNorm2d(16, track_running_stats=False),\n","            nn.ReLU(True)\n","        )\n","\n","    def forward(self, x):\n","\n","        #block1\n","        enc1 = self.encoder1(x)\n","        enc2 = self.encoder2(self.pool1(enc1))\n","        enc3 = self.encoder3(self.pool2(enc2))\n","        enc4 = self.encoder4(self.pool3(enc3))\n","\n","        bottleneck = self.bottleneck(self.pool4(enc4))\n","\n","        dec4 = self.upconv4(bottleneck)\n","        dec4 = torch.cat((dec4, enc4), dim=1)\n","        dec4 = self.decoder4(dec4)\n","        dec3 = self.upconv3(dec4)\n","        dec3 = torch.cat((dec3, enc3), dim=1)\n","        dec3 = self.decoder3(dec3)\n","        dec2 = self.upconv2(dec3)\n","        dec2 = torch.cat((dec2, enc2), dim=1)\n","        dec2 = self.decoder2(dec2)\n","        dec1 = self.upconv1(dec2)\n","        dec1 = torch.cat((dec1, enc1), dim=1)\n","        dec1 = self.decoder1(dec1)\n","        coonv1_1 = self.conv(dec1)\n","\n","        \n","        #block2 \n","        enc1_2 = self.encoder1(coonv1_1)\n","        enc2_2 = self.encoder2(self.pool1(enc1_2))\n","        enc3_2 = self.encoder3(self.pool2(enc2_2))\n","        enc4_2 = self.encoder4(self.pool3(enc3_2))\n","\n","        bottleneck_2 = self.bottleneck(self.pool4(enc4_2))\n","\n","        dec4_2 = self.upconv4(bottleneck_2)\n","        dec4_2 = torch.cat((dec4_2, enc4_2), dim=1)\n","        dec4_2 = self.decoder4(dec4_2)\n","        dec3_2 = self.upconv3(dec4_2)\n","        dec3_2 = torch.cat((dec3_2, enc3_2), dim=1)\n","        dec3_2 = self.decoder3(dec3_2)\n","        dec2_2 = self.upconv2(dec3_2)\n","        dec2_2 = torch.cat((dec2_2, enc2_2), dim=1)\n","        dec2_2 = self.decoder2(dec2_2)\n","        dec1_2 = self.upconv1(dec2_2)\n","        dec1_2 = torch.cat((dec1_2, enc1_2), dim=1)\n","        dec1_2 = self.decoder1(dec1_2)\n","        coonv1_2 = self.conv(dec1_2)\n","\n","\n","        \n","        #block3\n","        enc1_3 = self.encoder1(coonv1_2)\n","        enc2_3 = self.encoder2(self.pool1(enc1_3))\n","        enc3_3 = self.encoder3(self.pool2(enc2_3))\n","        enc4_3 = self.encoder4(self.pool3(enc3_3))\n","\n","        bottleneck_3 = self.bottleneck(self.pool4(enc4_3))\n","\n","        dec4_3 = self.upconv4(bottleneck_3)\n","        dec4_3 = torch.cat((dec4_3, enc4_3), dim=1)\n","        dec4_3 = self.decoder4(dec4_3)\n","        dec3_3 = self.upconv3(dec4_3)\n","        dec3_3 = torch.cat((dec3_3, enc3_3), dim=1)\n","        dec3_3 = self.decoder3(dec3_3)\n","        dec2_3 = self.upconv2(dec3_3)\n","        dec2_3 = torch.cat((dec2_3, enc2_3), dim=1)\n","        dec2_3 = self.decoder2(dec2_3)\n","        dec1_3 = self.upconv1(dec2_3)\n","        dec1_3 = torch.cat((dec1_3, enc1_3), dim=1)\n","        dec1_3 = self.decoder1(dec1_3)\n","        coonv1_3 = self.conv(dec1_3)\n","\n","\n","        #block4\n","        enc1_4 = self.encoder1(coonv1_3)\n","        enc2_4 = self.encoder2(self.pool1(enc1_4))\n","        enc3_4 = self.encoder3(self.pool2(enc2_4))\n","        enc4_4 = self.encoder4(self.pool3(enc3_4))\n","\n","        bottleneck_4 = self.bottleneck(self.pool4(enc4_4))\n","\n","        dec4_4 = self.upconv4(bottleneck_4)\n","        dec4_4 = torch.cat((dec4_4, enc4_4), dim=1)\n","        dec4_4 = self.decoder4(dec4_4)\n","        dec3_4 = self.upconv3(dec4_4)\n","        dec3_4 = torch.cat((dec3_4, enc3_4), dim=1)\n","        dec3_4 = self.decoder3(dec3_4)\n","        dec2_4 = self.upconv2(dec3_4)\n","        dec2_4 = torch.cat((dec2_4, enc2_4), dim=1)\n","        dec2_4 = self.decoder2(dec2_4)\n","        dec1_4 = self.upconv1(dec2_4)\n","        dec1_4 = torch.cat((dec1_4, enc1_4), dim=1)\n","        dec1_4 = self.decoder1(dec1_4)\n","        coonv1_4 = self.conv(dec1_4)\n","\n","        #concatenation of different UNet feature maps\n","        concat = torch.cat((coonv1_1, coonv1_2, coonv1_3, coonv1_4  ), dim=1)\n","\n","\n","        #pyramid convolution\n","        conv_pyramid_3 =  self.pyramid_3(concat)\n","        conv_pyramid_5 =  self.pyramid_5(concat)\n","        conv_pyramid_7 =  self.pyramid_7(concat)\n","        conv_pyramid_11 =  self.pyramid_11(concat)\n","        conv_pyramid_17 =  self.pyramid_17(concat)\n","        conv_pyramid_25 =  self.pyramid_25(concat)\n","        conv_pyramid_35 =  self.pyramid_35(concat)\n","        conv_pyramid_45 =  self.pyramid_45(concat)\n","\n","        #concatenation of feature maps corresponding different convolution filters present in Pyramid convolution layer\n","        concat_py = torch.cat(( conv_pyramid_3, conv_pyramid_5, conv_pyramid_7, conv_pyramid_11, conv_pyramid_17, conv_pyramid_25, conv_pyramid_35, conv_pyramid_45), dim=1)\n","      \n","        return torch.sigmoid(self.conv_1(concat_py))\n","\n","    @staticmethod\n","    def _block(in_channels, features, name):\n","        return nn.Sequential(\n","            OrderedDict(\n","                [\n","                    (\n","                        name + \"conv1\",\n","                        nn.Conv2d(\n","                            in_channels=in_channels,\n","                            out_channels=features,\n","                            kernel_size=3,\n","                            padding=1,\n","                            bias=False,\n","                        ),\n","                    ),\n","                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n","                    (name + \"relu1\", nn.ReLU(inplace=True)),\n","                    (\n","                        name + \"conv2\",\n","                        nn.Conv2d(\n","                            in_channels=features,\n","                            out_channels=features,\n","                            kernel_size=3,\n","                            padding=1,\n","                            bias=False,\n","                        ),\n","                    ),\n","                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n","                    (name + \"relu2\", nn.ReLU(inplace=True)),\n","                ]\n","            )\n","        )"]},{"cell_type":"markdown","metadata":{"id":"ZzLeMds8bglC"},"source":["Defining our Discriminator"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":421,"status":"ok","timestamp":1638352107082,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"Zk5I8Q_mAAAm"},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, in_channels, use_sigmoid=True, use_spectral_norm=True):\n","        super().__init__()\n","        self.use_sigmoid = use_sigmoid\n","\n","        self.conv1 = self.features = nn.Sequential(\n","            spectral_norm(nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","        self.conv2 = nn.Sequential(\n","            spectral_norm(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","        self.conv3 = nn.Sequential(\n","            spectral_norm(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","        self.conv4 = nn.Sequential(\n","            spectral_norm(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","        self.conv5 = nn.Sequential(\n","            spectral_norm(nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n","        )\n","\n","\n","    def forward(self, x):\n","        conv1 = self.conv1(x)\n","        conv2 = self.conv2(conv1)\n","        conv3 = self.conv3(conv2)\n","        conv4 = self.conv4(conv3)\n","        conv5 = self.conv5(conv4)\n","\n","        outputs = conv5\n","        if self.use_sigmoid:\n","            outputs = torch.sigmoid(conv5)\n","\n","        return outputs, [conv1, conv2, conv3, conv4, conv5]\n","\n","def spectral_norm(module, mode=True):\n","    if mode:\n","        return nn.utils.spectral_norm(module)\n","\n","    return module"]},{"cell_type":"markdown","metadata":{"id":"pqRl8shQbkm_"},"source":["Defining our loss functions"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1638352110739,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"0FLH3Z9lAAAo"},"outputs":[],"source":["class AdversarialLoss(nn.Module):\n","    r\"\"\"\n","    Adversarial loss\n","    https://arxiv.org/abs/1711.10337\n","    \"\"\"\n","\n","    def __init__(self, type='hinge', target_real_label=1.0, target_fake_label=0.0):\n","        r\"\"\"\n","        type = nsgan | lsgan | hinge\n","        \"\"\"\n","        super().__init__()\n","\n","        self.type = type\n","        self.register_buffer('real_label', torch.tensor(target_real_label))\n","        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n","\n","        if type == 'nsgan':\n","            self.criterion = nn.BCELoss()\n","\n","        elif type == 'lsgan':\n","            self.criterion = nn.MSELoss()\n","\n","        elif type == 'hinge':\n","            self.criterion = nn.ReLU()\n","\n","    def __call__(self, outputs, is_real, is_disc=None):\n","        if self.type == 'hinge':\n","            if is_real:\n","              return -torch.log(outputs).mean()\n","            else:\n","              return -torch.log(1-outputs).mean()\n","\n","\n","        else:\n","            labels = (self.real_label if is_real else self.fake_label).expand_as(outputs)\n","            loss = self.criterion(outputs, labels)\n","            return loss\n","\n","\n","\n","class ContentLoss(nn.Module):\n","    r\"\"\"\n","    Perceptual loss, VGG-based\n","    https://arxiv.org/abs/1603.08155\n","    https://github.com/dxyang/StyleTransfer/blob/master/utils.py\n","    \"\"\"\n","\n","    def __init__(self, weights=[1.0, 1.0, 1.0, 1.0, 1.0]):\n","        super().__init__()\n","        self.add_module('vgg', VGG19().cuda())\n","        self.criterion = torch.nn.L1Loss().cuda()\n","        self.weights = weights\n","\n","    def __call__(self, x, y):\n","        # Compute features\n","        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n","\n","        content_loss = 0.0\n","        content_loss += self.weights[0] * self.criterion(x_vgg['relu1_1'], y_vgg['relu1_1'])\n","        content_loss += self.weights[1] * self.criterion(x_vgg['relu2_1'], y_vgg['relu2_1'])\n","        content_loss += self.weights[2] * self.criterion(x_vgg['relu3_1'], y_vgg['relu3_1'])\n","        content_loss += self.weights[3] * self.criterion(x_vgg['relu4_1'], y_vgg['relu4_1'])\n","        content_loss += self.weights[4] * self.criterion(x_vgg['relu5_1'], y_vgg['relu5_1'])\n","\n","\n","        return content_loss\n","\n","\n","\n","class VGG19(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        features = models.vgg19(pretrained=True).features\n","        self.relu1_1 = torch.nn.Sequential()\n","        self.relu1_2 = torch.nn.Sequential()\n","\n","        self.relu2_1 = torch.nn.Sequential()\n","        self.relu2_2 = torch.nn.Sequential()\n","\n","        self.relu3_1 = torch.nn.Sequential()\n","        self.relu3_2 = torch.nn.Sequential()\n","        self.relu3_3 = torch.nn.Sequential()\n","        self.relu3_4 = torch.nn.Sequential()\n","\n","        self.relu4_1 = torch.nn.Sequential()\n","        self.relu4_2 = torch.nn.Sequential()\n","        self.relu4_3 = torch.nn.Sequential()\n","        self.relu4_4 = torch.nn.Sequential()\n","\n","        self.relu5_1 = torch.nn.Sequential()\n","        self.relu5_2 = torch.nn.Sequential()\n","        self.relu5_3 = torch.nn.Sequential()\n","        self.relu5_4 = torch.nn.Sequential()\n","\n","        for x in range(2):\n","            self.relu1_1.add_module(str(x), features[x])\n","\n","        for x in range(2, 4):\n","            self.relu1_2.add_module(str(x), features[x])\n","\n","        for x in range(4, 7):\n","            self.relu2_1.add_module(str(x), features[x])\n","\n","        for x in range(7, 9):\n","            self.relu2_2.add_module(str(x), features[x])\n","\n","        for x in range(9, 12):\n","            self.relu3_1.add_module(str(x), features[x])\n","\n","        for x in range(12, 14):\n","            self.relu3_2.add_module(str(x), features[x])\n","\n","        for x in range(14, 16):\n","            self.relu3_3.add_module(str(x), features[x])\n","\n","        for x in range(16, 18):\n","            self.relu3_4.add_module(str(x), features[x])\n","\n","        for x in range(18, 21):\n","            self.relu4_1.add_module(str(x), features[x])\n","\n","        for x in range(21, 23):\n","            self.relu4_2.add_module(str(x), features[x])\n","\n","        for x in range(23, 25):\n","            self.relu4_3.add_module(str(x), features[x])\n","\n","        for x in range(25, 27):\n","            self.relu4_4.add_module(str(x), features[x])\n","\n","        for x in range(27, 30):\n","            self.relu5_1.add_module(str(x), features[x])\n","\n","        for x in range(30, 32):\n","            self.relu5_2.add_module(str(x), features[x])\n","\n","        for x in range(32, 34):\n","            self.relu5_3.add_module(str(x), features[x])\n","\n","        for x in range(34, 36):\n","            self.relu5_4.add_module(str(x), features[x])\n","\n","        # don't need the gradients, just want the features\n","        for param in self.parameters():\n","            param.requires_grad = False\n","\n","    def forward(self, x):\n","        relu1_1 = self.relu1_1(x)\n","        relu1_2 = self.relu1_2(relu1_1)\n","\n","        relu2_1 = self.relu2_1(relu1_2)\n","        relu2_2 = self.relu2_2(relu2_1)\n","\n","        relu3_1 = self.relu3_1(relu2_2)\n","        relu3_2 = self.relu3_2(relu3_1)\n","        relu3_3 = self.relu3_3(relu3_2)\n","        relu3_4 = self.relu3_4(relu3_3)\n","\n","        relu4_1 = self.relu4_1(relu3_4)\n","        relu4_2 = self.relu4_2(relu4_1)\n","        relu4_3 = self.relu4_3(relu4_2)\n","        relu4_4 = self.relu4_4(relu4_3)\n","\n","        relu5_1 = self.relu5_1(relu4_4)\n","        relu5_2 = self.relu5_2(relu5_1)\n","        relu5_3 = self.relu5_3(relu5_2)\n","        relu5_4 = self.relu5_4(relu5_3)\n","\n","        out = {\n","            'relu1_1': relu1_1,\n","            'relu1_2': relu1_2,\n","\n","            'relu2_1': relu2_1,\n","            'relu2_2': relu2_2,\n","\n","            'relu3_1': relu3_1,\n","            'relu3_2': relu3_2,\n","            'relu3_3': relu3_3,\n","            'relu3_4': relu3_4,\n","\n","            'relu4_1': relu4_1,\n","            'relu4_2': relu4_2,\n","            'relu4_3': relu4_3,\n","            'relu4_4': relu4_4,\n","\n","            'relu5_1': relu5_1,\n","            'relu5_2': relu5_2,\n","            'relu5_3': relu5_3,\n","            'relu5_4': relu5_4,\n","        }\n","        return out"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1638352113016,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"nCVcqVjAAAAr"},"outputs":[],"source":["def gaussian(window_size, sigma):\n","    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n","    return gauss/gauss.sum()\n","\n","def create_window(window_size, channel):\n","    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n","    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n","    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n","    return window\n","\n","def _ssim(img1, img2, window, window_size, channel, size_average = True):\n","    mu1 = F3.conv2d(img1, window, padding = window_size//2, groups = channel)\n","    mu2 = F3.conv2d(img2, window, padding = window_size//2, groups = channel)\n","\n","    mu1_sq = mu1.pow(2)\n","    mu2_sq = mu2.pow(2)\n","    mu1_mu2 = mu1*mu2\n","\n","    sigma1_sq = F3.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n","    sigma2_sq = F3.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n","    sigma12 = F3.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n","\n","    C1 = 0.01**2\n","    C2 = 0.03**2\n","\n","    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n","\n","    if size_average:\n","        return ssim_map.mean()\n","    else:\n","        return ssim_map.mean(1).mean(1).mean(1)\n","\n","class SSIM(torch.nn.Module):\n","    def __init__(self, window_size = 11, size_average = True):\n","        super(SSIM, self).__init__()\n","        self.window_size = window_size\n","        self.size_average = size_average\n","        self.channel = 1\n","        self.window = create_window(window_size, self.channel)\n","\n","    def forward(self, img1, img2):\n","        (_, channel, _, _) = img1.size()\n","\n","        if channel == self.channel and self.window.data.type() == img1.data.type():\n","            window = self.window\n","        else:\n","            window = create_window(self.window_size, channel)\n","            \n","            if img1.is_cuda:\n","                window = window.cuda(img1.get_device())\n","            window = window.type_as(img1)\n","            \n","            self.window = window\n","            self.channel = channel\n","\n","\n","        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n","\n","def ssim(img1, img2, window_size = 11, size_average = True):\n","    (_, channel, _, _) = img1.size()\n","    window = create_window(window_size, channel)\n","    \n","    if img1.is_cuda:\n","        window = window.cuda(img1.get_device())\n","    window = window.type_as(img1)\n","    \n","    return _ssim(img1, img2, window, window_size, channel, size_average)"]},{"cell_type":"markdown","metadata":{"id":"KtvXXCtxboWU"},"source":["Defining our model i.e. DU_Net"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":785,"status":"ok","timestamp":1638352114995,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"SNTpEUunAAAw"},"outputs":[],"source":["class DU_Net(nn.Module):\n","\n","    def __init__(self, unet_input, unet_output, discriminator_input):\n","        super().__init__()\n","\n","\n","        unet = UNet(in_channels=unet_input ,out_channels=unet_output)\n","        unet = nn.DataParallel(unet, device_ids=[0,1])\n","        unet = unet.cuda()\n","\n","        discriminator = Discriminator(in_channels=discriminator_input , use_sigmoid=True)\n","        discriminator = nn.DataParallel(discriminator, device_ids=[0,1])\n","        discriminator = discriminator.cuda()\n","\n","        criterion = nn.MSELoss()\n","        adversarial_loss = AdversarialLoss(type='hinge')\n","        l1_loss = nn.L1Loss()\n","        content_loss = ContentLoss()\n","        ssim = SSIM(window_size = 11)\n","        bce = nn.BCELoss()\n","\n","        self.add_module('unet', unet)\n","        self.add_module('discriminator', discriminator)\n","\n","        self.add_module('criterion', criterion)\n","        self.add_module('adversarial_loss', adversarial_loss)\n","        self.add_module('l1_loss', l1_loss)\n","        self.add_module('content_loss', content_loss)\n","        self.add_module('ssim_loss', ssim)\n","        self.add_module('bce_loss', bce)\n","        \n","\n","        self.unet_optimizer = optim.Adam(\n","            unet.parameters(), \n","            lr = float(0.001),\n","            betas=(0.9, 0.999)\n","            )\n","\n","        self.dis_optimizer = optim.Adam(\n","             params=discriminator.parameters(),\n","             lr=float(0.001),\n","             betas=(0.9, 0.999)\n","             )\n","\n","        self.unet_input = unet_input\n","        self.unet_output = unet_output\n","        self.discriminator_input = discriminator_input\n","\n","\n","    def load(self, path_unet, path_discriminator):\n","        weight_unet = torch.load(path_unet)\n","        weight_discriminator = torch.load(path_discriminator)\n","        self.unet.load_state_dict(weight_unet)\n","        self.discriminator.load_state_dict(weight_discriminator)\n","\n","    def save_weight(self, path_unet, path_dis):\n","        torch.save(self.unet.state_dict(), path_unet)\n","        torch.save(self.discriminator.state_dict(), path_dis)\n","\n","    def process(self, haze_images, dehaze_images):\n","\n","        # zero optimizers\n","        self.unet_optimizer.zero_grad()\n","        self.dis_optimizer.zero_grad()\n","\n","\n","        # find output and initialize loss to zero\n","        unet_loss = 0\n","        dis_loss = 0\n","\n","        outputs = self.unet(haze_images.cuda())\n","\n","        # unet loss\n","        unet_fake, unet_fake_feat = self.discriminator(outputs.cuda())        \n","        unet_gan_loss = self.adversarial_loss(unet_fake, True, False) * 0.7\n","        unet_loss += unet_gan_loss\n","\n","        unet_criterion = self.criterion(outputs.cuda(), dehaze_images.cuda())\n","        unet_loss += unet_criterion\n","\n","\n","\n","\n","        gen_content_loss = self.content_loss(outputs.cuda(), dehaze_images.cuda())\n","        gen_content_loss = (gen_content_loss * 0.7).cuda()\n","        unet_loss += gen_content_loss.cuda()\n","        \n","        \n","        ssim_loss =  self.ssim_loss(outputs.cuda(), dehaze_images.cuda())\n","        ssim_loss = (1-ssim_loss)*2\n","        unet_loss += ssim_loss.cuda()\n","\n","        # discriminator loss\n","        dis_real, dis_real_feat = self.discriminator(dehaze_images.cuda())        \n","        dis_fake, dis_fake_feat = self.discriminator(outputs.detach().cuda())       \n","        dis_real_loss = self.adversarial_loss(dis_real, True, True)\n","        dis_fake_loss = self.adversarial_loss(dis_fake, False, True)\n","        dis_loss += (dis_real_loss + dis_fake_loss) / 2\n","\n","\n","        return unet_loss, dis_loss, unet_criterion, 1-ssim_loss/2\n","\n","    def backward(self, unet_loss, dis_loss):\n","        unet_loss.backward()\n","        self.unet_optimizer.step()\n","        \n","        dis_loss.backward(retain_graph = True)\n","        self.dis_optimizer.step()\n","\n","\n","    def predict(self, haze_images):\n","      predict_mask = self.unet(haze_images.cuda())\n","      return predict_mask"]},{"cell_type":"markdown","metadata":{"id":"d5NG1aLzbtmE"},"source":["Defining our and creating the data loader"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1078,"status":"ok","timestamp":1638352118035,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"B4Zt47MJAAA0","outputId":"d2e4c6d4-f62f-4109-8398-fbf981cb88ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["['O-Haze/train/haze/10_outdoor_hazy.jpg', 'O-Haze/train/haze/31_outdoor_hazy.jpg', 'O-Haze/train/haze/25_outdoor_hazy.jpg', 'O-Haze/train/haze/40_outdoor_hazy.jpg', 'O-Haze/train/haze/04_outdoor_hazy.jpg', 'O-Haze/train/haze/21_outdoor_hazy.JPG', 'O-Haze/train/haze/35_outdoor_hazy.jpg', 'O-Haze/train/haze/14_outdoor_hazy.jpg', 'O-Haze/train/haze/30_outdoor_hazy.jpg', 'O-Haze/train/haze/11_outdoor_hazy.jpg', 'O-Haze/train/haze/05_outdoor_hazy.jpg', 'O-Haze/train/haze/24_outdoor_hazy.jpg', 'O-Haze/train/haze/20_outdoor_hazy.jpg', 'O-Haze/train/haze/01_outdoor_hazy.jpg', 'O-Haze/train/haze/15_outdoor_hazy.jpg', 'O-Haze/train/haze/34_outdoor_hazy.jpg', 'O-Haze/train/haze/06_outdoor_hazy.jpg', 'O-Haze/train/haze/38_outdoor_hazy.jpg', 'O-Haze/train/haze/19_outdoor_hazy.jpg', 'O-Haze/train/haze/27_outdoor_hazy.jpg', 'O-Haze/train/haze/33_outdoor_hazy.jpg', 'O-Haze/train/haze/12_outdoor_hazy.jpg', 'O-Haze/train/haze/28_outdoor_hazy.jpg', 'O-Haze/train/haze/16_outdoor_hazy.jpg', 'O-Haze/train/haze/37_outdoor_hazy.jpg', 'O-Haze/train/haze/09_outdoor_hazy.jpg', 'O-Haze/train/haze/23_outdoor_hazy.jpg', 'O-Haze/train/haze/02_outdoor_hazy.jpg', 'O-Haze/train/haze/18_outdoor_hazy.jpg', 'O-Haze/train/haze/26_outdoor_hazy.jpg', 'O-Haze/train/haze/07_outdoor_hazy.jpg', 'O-Haze/train/haze/39_outdoor_hazy.jpg', 'O-Haze/train/haze/13_outdoor_hazy.jpg', 'O-Haze/train/haze/32_outdoor_hazy.jpg', 'O-Haze/train/haze/36_outdoor_hazy.jpg', 'O-Haze/train/haze/08_outdoor_hazy.jpg', 'O-Haze/train/haze/29_outdoor_hazy.jpg', 'O-Haze/train/haze/17_outdoor_hazy.jpg', 'O-Haze/train/haze/03_outdoor_hazy.JPG', 'O-Haze/train/haze/22_outdoor_hazy.jpg', 'O-Haze/train/haze/41_outdoor_hazy.jpg', 'O-Haze/train/haze/42_outdoor_hazy.jpg', 'O-Haze/train/haze/43_outdoor_hazy.jpg', 'O-Haze/train/haze/44_outdoor_hazy.jpg', 'O-Haze/train/haze/45_outdoor_hazy.jpg']\n"]}],"source":["class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, haze_list, dehaze_list, augment=False):\n","        super().__init__()\n","        print(haze_list)\n","        self.augment = augment\n","        self.haze_list = haze_list\n","        self.dehaze_list = dehaze_list\n","        \n","    def __len__(self):\n","        # return 45\n","        return 210\n","\n","    def __getitem__(self, index):\n","        try:\n","            item = self.load_item(index)\n","        except:\n","            print('loading error: ' + self.haze_list[index])\n","            item = self.load_item(0)\n","            \n","\n","        return item\n","\n","\n","    def load_item(self, index):\n","        val = 1024*2           #crop size i.e hight and width\n","        size_data = 25         #depends on the no. of training images in the dataset\n","        height_data = 4657     #heigth of the training images\n","        width_data = 2833      #width of the training images\n","\n","        numx = random.randint(0, height_data-val)\n","        numy = random.randint(0, width_data-val)\n","\n","        haze_image = cv2.imread(self.haze_list[index%size_data])\n","        dehaze_image = cv2.imread(self.dehaze_list[index%size_data])\n","        haze_image = Image.fromarray(haze_image)\n","        dehaze_image = Image.fromarray(dehaze_image)\n","\n","        haze_crop=haze_image.crop((numx, numy, numx+val, numy+val))\n","        dehaze_crop=dehaze_image.crop((numx, numy, numx+val, numy+val))\n"," \n","        haze_crop = haze_crop.resize((512,512), resample=PIL.Image.BICUBIC)\n","        dehaze_crop = dehaze_crop.resize((512,512), resample=PIL.Image.BICUBIC)\n","\n","        haze_crop = np.array(haze_crop)\n","        dehaze_crop = np.array(dehaze_crop)\n","        haze_crop = cv2.cvtColor(haze_crop, cv2.COLOR_BGR2YCrCb)\n","        dehaze_crop = cv2.cvtColor(dehaze_crop, cv2.COLOR_BGR2YCrCb)\n","        haze_crop = self.to_tensor(haze_crop).cuda()\n","        dehaze_crop = self.to_tensor(dehaze_crop).cuda()\n","        \n","        return haze_crop.cuda(), dehaze_crop.cuda()\n","    \n","    def to_tensor(self, img):\n","        img_t = F.to_tensor(img).float()\n","        return img_t\n","\n","\n","    def create_iterator(self, batch_size):\n","        while True:\n","            sample_loader = DataLoader(\n","                dataset=self,\n","                batch_size=batch_size,\n","                drop_last=True\n","            )\n","\n","            for item in sample_loader:\n","                yield item\n","\n","\n","path_of_train_hazy_images = 'O-Haze/train/haze/*'\n","path_of_train_gt_images = 'O-Haze/train/gt/*'\n","\n","images_paths_train_gt=glob.glob(path_of_train_gt_images)\n","image_paths_train_hazy=glob.glob(path_of_train_hazy_images)\n","\n","train_dataset = Dataset(image_paths_train_hazy, images_paths_train_gt, augment=False)\n","\n","train_loader = DataLoader(\n","            dataset=train_dataset,\n","            batch_size=2,\n","            num_workers=0,\n","            drop_last=True,\n","            shuffle=False\n","        )"]},{"cell_type":"markdown","metadata":{"id":"DQW0X3g5dNBX"},"source":["Creating the model"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107,"referenced_widgets":["ebe9a67a932540f5915ea51ec0a5270a","f7c88cdd25194de19710363de98990aa","d34e39b5242f4a9da3e0d1bc428b9e13","5fea42f5b82c464895c39da4c89bc001","2182e0fd245b47c6a4b2effc75772271","00bd30886cab4fe682e25a897b7dde9c","39b1407cce964ccc80dde8685c296bb7","b67b16690dc8453faf8c4b5e3866d3db"]},"executionInfo":{"elapsed":45130,"status":"ok","timestamp":1638352164500,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"ZACwe8ObAABE","outputId":"3061fba1-65cd-4e29-f909-bad0ccdf258d"},"outputs":[],"source":["graph_gloss = []\n","input_unet_channel = 3\n","output_unet_channel = 3\n","input_dis_channel = 3\n","max_epochs = 100\n","DUNet = DU_Net(input_unet_channel ,output_unet_channel ,input_dis_channel).cuda()"]},{"cell_type":"markdown","metadata":{"id":"Gb7PvZASdQn1"},"source":["Training function"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1638352205088,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"AFZtJGoY5nu-","outputId":"2762182e-c144-453f-d39d-00cf06fad6fd"},"outputs":[{"data":{"text/plain":["'weight/20211201_lr0.001_generator_0.pth'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["a = \"weight/{}_generator_{}.pth\".format(\"20211201_lr0.001\", 0)\n","a"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":801,"status":"ok","timestamp":1638352238710,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"24-9evbnAABM"},"outputs":[],"source":["def train(max_epochs, current_epoch=0):\n","    for epoch in range(max_epochs):\n","        i=1\n","        mse_epoch = 0.0\n","        ssim_epoch = 0.0\n","        unet_epoch = 0.0\n","        for haze_images, dehaze_images, in train_loader:\n","            unet_loss, dis_loss, mse, ssim = DUNet.process(haze_images.cuda(), dehaze_images.cuda())\n","            DUNet.backward(unet_loss.cuda(), dis_loss.cuda())\n","            print('Epoch: '+str(epoch+current_epoch+1)+ ' || Batch: '+str(i)+ \" || unet loss: \"+str(unet_loss.cpu().item()) + \" || dis loss: \"+str(dis_loss.cpu().item()) + \" || mse: \"+str(mse.cpu().item()) + \" | ssim:\" + str(ssim.cpu().item()) )\n","            mse_epoch =  mse_epoch + mse.cpu().item() \n","            ssim_epoch = ssim_epoch + ssim.cpu().item()\n","            unet_epoch = unet_epoch + unet_loss.cpu().item()\n","            i=i+1\n","        \n","        print()\n","        mse_epoch = mse_epoch/i\n","        ssim_epoch = ssim_epoch/i\n","        unet_epoch = unet_epoch/i\n","        graph_gloss.append(ssim_epoch)\n","        print(\"mse: + \"+str(mse_epoch) + \" | ssim: \"+ str(ssim_epoch)+ \" | unet:\"+str(unet_epoch))\n","        \n","        path_of_generator_weight = \"weight/{}_generator_{}.pth\".format(\"hj_train_211201_lr0.001\", epoch + current_epoch)  #path for storing the weights of genertaor\n","        path_of_discriminator_weight = \"weight/{}_discriminator_{}.pth\".format(\"hj_train_20211201_lr0.001\", epoch + current_epoch)  #path for storing the weights of discriminator\n","        \n","        DUNet.save_weight(path_of_generator_weight,path_of_discriminator_weight)\n","        print()"]},{"cell_type":"markdown","metadata":{"id":"29CCGgMDdTPe"},"source":["Calling training function"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":406,"status":"ok","timestamp":1638352253370,"user":{"displayName":"HJ Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10292621205428392172"},"user_tz":-480},"id":"QneiMAy2UW4N"},"outputs":[],"source":["from PIL import Image"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '3,4'"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":171},"id":"rmEpSm9jAABP","outputId":"0f15a3f4-a396-4ca6-f10a-7d8187412b26"},"outputs":[{"name":"stderr","output_type":"stream","text":["/data/jkimbf/miniconda3/envs/bpp_net/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1 || Batch: 1 || unet loss: 3.2065908908843994 || dis loss: 0.6852442026138306 || mse: 0.05460687726736069 | ssim:0.311537504196167\n","Epoch: 1 || Batch: 2 || unet loss: 2.9259696006774902 || dis loss: 1.4631799459457397 || mse: 0.026737049221992493 | ssim:0.34311819076538086\n","Epoch: 1 || Batch: 3 || unet loss: 3.381204605102539 || dis loss: 0.9318884015083313 || mse: 0.03181526064872742 | ssim:0.5972573757171631\n","Epoch: 1 || Batch: 4 || unet loss: 2.6812868118286133 || dis loss: 0.7000583410263062 || mse: 0.02993026189506054 | ssim:0.5940541625022888\n","Epoch: 1 || Batch: 5 || unet loss: 2.2994399070739746 || dis loss: 0.6944947242736816 || mse: 0.022216912358999252 | ssim:0.6845197677612305\n","Epoch: 1 || Batch: 6 || unet loss: 2.275395393371582 || dis loss: 0.6916514039039612 || mse: 0.024191293865442276 | ssim:0.722378671169281\n","Epoch: 1 || Batch: 7 || unet loss: 2.2796058654785156 || dis loss: 0.7326505184173584 || mse: 0.02392113022506237 | ssim:0.6533269286155701\n","Epoch: 1 || Batch: 8 || unet loss: 1.6822397708892822 || dis loss: 0.8977395296096802 || mse: 0.028058703988790512 | ssim:0.7461162805557251\n","Epoch: 1 || Batch: 9 || unet loss: 1.6454092264175415 || dis loss: 0.9677127003669739 || mse: 0.053254514932632446 | ssim:0.6711009740829468\n","Epoch: 1 || Batch: 10 || unet loss: 1.7027251720428467 || dis loss: 0.8343479633331299 || mse: 0.03150799497961998 | ssim:0.7198710441589355\n","Epoch: 1 || Batch: 11 || unet loss: 1.9265319108963013 || dis loss: 0.7292918562889099 || mse: 0.015970546752214432 | ssim:0.733298659324646\n","Epoch: 1 || Batch: 12 || unet loss: 2.0202207565307617 || dis loss: 0.680365264415741 || mse: 0.04410500079393387 | ssim:0.6745797991752625\n","Epoch: 1 || Batch: 13 || unet loss: 2.036518096923828 || dis loss: 0.6963102221488953 || mse: 0.018596621230244637 | ssim:0.7271217107772827\n","Epoch: 1 || Batch: 14 || unet loss: 1.8477686643600464 || dis loss: 0.7257117033004761 || mse: 0.03034968301653862 | ssim:0.7133366465568542\n","Epoch: 1 || Batch: 15 || unet loss: 1.8139663934707642 || dis loss: 0.7874918580055237 || mse: 0.021817903965711594 | ssim:0.7480710744857788\n","Epoch: 1 || Batch: 16 || unet loss: 2.0294156074523926 || dis loss: 0.8283752202987671 || mse: 0.02132565528154373 | ssim:0.7089757323265076\n","Epoch: 1 || Batch: 17 || unet loss: 1.644372582435608 || dis loss: 0.8051931858062744 || mse: 0.05319972336292267 | ssim:0.6960293650627136\n","Epoch: 1 || Batch: 18 || unet loss: 1.7816332578659058 || dis loss: 0.7547988295555115 || mse: 0.027607306838035583 | ssim:0.751414954662323\n","Epoch: 1 || Batch: 19 || unet loss: 2.159496784210205 || dis loss: 0.6952388882637024 || mse: 0.02071293257176876 | ssim:0.6949217319488525\n","Epoch: 1 || Batch: 20 || unet loss: 1.5602166652679443 || dis loss: 0.6206722259521484 || mse: 0.046046264469623566 | ssim:0.7248075008392334\n","Epoch: 1 || Batch: 21 || unet loss: 1.6284472942352295 || dis loss: 0.5988147854804993 || mse: 0.05061623454093933 | ssim:0.7122844457626343\n","Epoch: 1 || Batch: 22 || unet loss: 1.8347053527832031 || dis loss: 0.6188133358955383 || mse: 0.032037392258644104 | ssim:0.7082093954086304\n","Epoch: 1 || Batch: 23 || unet loss: 1.873927116394043 || dis loss: 0.6945562958717346 || mse: 0.014845294877886772 | ssim:0.7584866285324097\n","Epoch: 1 || Batch: 24 || unet loss: 1.7931320667266846 || dis loss: 0.6991977691650391 || mse: 0.02292831800878048 | ssim:0.7402567267417908\n","Epoch: 1 || Batch: 25 || unet loss: 1.6882190704345703 || dis loss: 0.7707041501998901 || mse: 0.00801786594092846 | ssim:0.7452656626701355\n","Epoch: 1 || Batch: 26 || unet loss: 1.949035406112671 || dis loss: 0.7367789149284363 || mse: 0.013943806290626526 | ssim:0.7358592748641968\n","Epoch: 1 || Batch: 27 || unet loss: 1.8164713382720947 || dis loss: 0.6422358751296997 || mse: 0.024191658943891525 | ssim:0.7096023559570312\n","Epoch: 1 || Batch: 28 || unet loss: 2.0047576427459717 || dis loss: 0.6098551750183105 || mse: 0.015445558354258537 | ssim:0.75071781873703\n","Epoch: 1 || Batch: 29 || unet loss: 2.07661771774292 || dis loss: 0.600632905960083 || mse: 0.01749732904136181 | ssim:0.7320847511291504\n","Epoch: 1 || Batch: 30 || unet loss: 1.8540092706680298 || dis loss: 0.6055430173873901 || mse: 0.02642730437219143 | ssim:0.7164337038993835\n","Epoch: 1 || Batch: 31 || unet loss: 1.8095916509628296 || dis loss: 0.6952741742134094 || mse: 0.015898698940873146 | ssim:0.7758922576904297\n","Epoch: 1 || Batch: 32 || unet loss: 1.943860650062561 || dis loss: 0.7665190696716309 || mse: 0.03079657256603241 | ssim:0.6727175116539001\n","Epoch: 1 || Batch: 33 || unet loss: 1.6326688528060913 || dis loss: 0.756781816482544 || mse: 0.016481954604387283 | ssim:0.7948815226554871\n","Epoch: 1 || Batch: 34 || unet loss: 1.6487303972244263 || dis loss: 0.5886867046356201 || mse: 0.03476124629378319 | ssim:0.6910037398338318\n","Epoch: 1 || Batch: 35 || unet loss: 1.699141025543213 || dis loss: 0.6123281121253967 || mse: 0.028709445148706436 | ssim:0.7070941925048828\n","Epoch: 1 || Batch: 36 || unet loss: 1.9868394136428833 || dis loss: 0.7135564088821411 || mse: 0.00951207336038351 | ssim:0.7466837763786316\n","Epoch: 1 || Batch: 37 || unet loss: 2.0051865577697754 || dis loss: 0.6493857502937317 || mse: 0.011553551070392132 | ssim:0.7035007476806641\n","Epoch: 1 || Batch: 38 || unet loss: 1.9075291156768799 || dis loss: 0.9847609996795654 || mse: 0.020334571599960327 | ssim:0.7285062074661255\n","Epoch: 1 || Batch: 39 || unet loss: 1.887056827545166 || dis loss: 0.8495448231697083 || mse: 0.010123249143362045 | ssim:0.7331970930099487\n","Epoch: 1 || Batch: 40 || unet loss: 1.7874929904937744 || dis loss: 0.8475470542907715 || mse: 0.009232563897967339 | ssim:0.7676666975021362\n","Epoch: 1 || Batch: 41 || unet loss: 1.8281162977218628 || dis loss: 0.6922783255577087 || mse: 0.017843587324023247 | ssim:0.7275876402854919\n","Epoch: 1 || Batch: 42 || unet loss: 1.8619965314865112 || dis loss: 0.655364990234375 || mse: 0.027890078723430634 | ssim:0.6888251304626465\n","Epoch: 1 || Batch: 43 || unet loss: 1.7314786911010742 || dis loss: 0.7531851530075073 || mse: 0.02043447643518448 | ssim:0.7496336698532104\n","Epoch: 1 || Batch: 44 || unet loss: 2.1134111881256104 || dis loss: 0.7805659174919128 || mse: 0.01638737879693508 | ssim:0.6892229914665222\n","Epoch: 1 || Batch: 45 || unet loss: 1.7243740558624268 || dis loss: 0.825268566608429 || mse: 0.013908247463405132 | ssim:0.7711283564567566\n","Epoch: 1 || Batch: 46 || unet loss: 1.5511232614517212 || dis loss: 0.6999527215957642 || mse: 0.02390722744166851 | ssim:0.6908885836601257\n","Epoch: 1 || Batch: 47 || unet loss: 1.9356414079666138 || dis loss: 0.7993993759155273 || mse: 0.01526640634983778 | ssim:0.720221996307373\n","Epoch: 1 || Batch: 48 || unet loss: 1.8405892848968506 || dis loss: 0.8502452969551086 || mse: 0.02343587577342987 | ssim:0.7502001523971558\n","Epoch: 1 || Batch: 49 || unet loss: 1.753058910369873 || dis loss: 0.7241083383560181 || mse: 0.02034303918480873 | ssim:0.714347243309021\n","Epoch: 1 || Batch: 50 || unet loss: 1.8207788467407227 || dis loss: 0.8191855549812317 || mse: 0.01618809811770916 | ssim:0.7215361595153809\n","Epoch: 1 || Batch: 51 || unet loss: 1.9555530548095703 || dis loss: 0.7921908497810364 || mse: 0.01826375722885132 | ssim:0.7088840007781982\n","Epoch: 1 || Batch: 52 || unet loss: 1.973609447479248 || dis loss: 0.8101099729537964 || mse: 0.019203631207346916 | ssim:0.6997655630111694\n","Epoch: 1 || Batch: 53 || unet loss: 1.8167744874954224 || dis loss: 0.7984371185302734 || mse: 0.015755001455545425 | ssim:0.7506081461906433\n","Epoch: 1 || Batch: 54 || unet loss: 1.9873933792114258 || dis loss: 0.8053344488143921 || mse: 0.015117056667804718 | ssim:0.7294200658798218\n","Epoch: 1 || Batch: 55 || unet loss: 1.6804574728012085 || dis loss: 0.7839157581329346 || mse: 0.019921790808439255 | ssim:0.7176582217216492\n","Epoch: 1 || Batch: 56 || unet loss: 2.016998767852783 || dis loss: 0.7982721328735352 || mse: 0.02060849964618683 | ssim:0.7459119558334351\n","Epoch: 1 || Batch: 57 || unet loss: 1.8511464595794678 || dis loss: 0.7622226476669312 || mse: 0.024686342105269432 | ssim:0.6515945196151733\n","Epoch: 1 || Batch: 58 || unet loss: 1.6057618856430054 || dis loss: 0.7875784635543823 || mse: 0.018473122268915176 | ssim:0.7816901206970215\n","Epoch: 1 || Batch: 59 || unet loss: 1.6490695476531982 || dis loss: 0.7516428828239441 || mse: 0.02178022265434265 | ssim:0.6874275207519531\n","Epoch: 1 || Batch: 60 || unet loss: 1.4562909603118896 || dis loss: 0.7355740070343018 || mse: 0.026461392641067505 | ssim:0.681451678276062\n","Epoch: 1 || Batch: 61 || unet loss: 1.6537542343139648 || dis loss: 0.7400678396224976 || mse: 0.025520507246255875 | ssim:0.6972349882125854\n","Epoch: 1 || Batch: 62 || unet loss: 1.6857191324234009 || dis loss: 0.7392556667327881 || mse: 0.0160122811794281 | ssim:0.6965624690055847\n","Epoch: 1 || Batch: 63 || unet loss: 2.039764642715454 || dis loss: 0.7577221989631653 || mse: 0.02423679083585739 | ssim:0.7068164348602295\n","Epoch: 1 || Batch: 64 || unet loss: 1.4650453329086304 || dis loss: 0.7296533584594727 || mse: 0.01855030655860901 | ssim:0.6943209171295166\n","Epoch: 1 || Batch: 65 || unet loss: 1.6452571153640747 || dis loss: 0.7571027278900146 || mse: 0.017563726752996445 | ssim:0.7574054598808289\n","Epoch: 1 || Batch: 66 || unet loss: 2.0195162296295166 || dis loss: 0.7746961712837219 || mse: 0.011896620504558086 | ssim:0.7310640215873718\n","Epoch: 1 || Batch: 67 || unet loss: 2.0653276443481445 || dis loss: 0.7782698273658752 || mse: 0.01949986070394516 | ssim:0.7126539945602417\n","Epoch: 1 || Batch: 68 || unet loss: 1.7193443775177002 || dis loss: 0.7496671676635742 || mse: 0.017976518720388412 | ssim:0.7357722520828247\n","Epoch: 1 || Batch: 69 || unet loss: 1.997649908065796 || dis loss: 0.7590939402580261 || mse: 0.01687406562268734 | ssim:0.7124168872833252\n","Epoch: 1 || Batch: 70 || unet loss: 1.5731247663497925 || dis loss: 0.7418980598449707 || mse: 0.016693120822310448 | ssim:0.759530246257782\n","Epoch: 1 || Batch: 71 || unet loss: 1.4908759593963623 || dis loss: 0.7052664756774902 || mse: 0.027661055326461792 | ssim:0.7105321884155273\n","Epoch: 1 || Batch: 72 || unet loss: 1.8987654447555542 || dis loss: 0.7270820736885071 || mse: 0.018586792051792145 | ssim:0.7223312258720398\n","Epoch: 1 || Batch: 73 || unet loss: 1.8432267904281616 || dis loss: 0.7320045828819275 || mse: 0.020016316324472427 | ssim:0.752592921257019\n","Epoch: 1 || Batch: 74 || unet loss: 1.734238862991333 || dis loss: 0.7022724151611328 || mse: 0.016172610223293304 | ssim:0.7152929306030273\n","Epoch: 1 || Batch: 75 || unet loss: 1.9681291580200195 || dis loss: 0.7100058794021606 || mse: 0.016526080667972565 | ssim:0.6898698806762695\n","Epoch: 1 || Batch: 76 || unet loss: 1.6639773845672607 || dis loss: 0.6703147888183594 || mse: 0.01931830495595932 | ssim:0.6966018676757812\n","Epoch: 1 || Batch: 77 || unet loss: 1.6008853912353516 || dis loss: 0.6833179593086243 || mse: 0.01715470477938652 | ssim:0.7039351463317871\n","Epoch: 1 || Batch: 78 || unet loss: 1.8066726922988892 || dis loss: 0.6963867545127869 || mse: 0.013765904121100903 | ssim:0.7535764575004578\n","Epoch: 1 || Batch: 79 || unet loss: 2.0407698154449463 || dis loss: 0.7000380754470825 || mse: 0.014188989996910095 | ssim:0.7298426628112793\n","Epoch: 1 || Batch: 80 || unet loss: 1.915500283241272 || dis loss: 0.6982991099357605 || mse: 0.01123300101608038 | ssim:0.7468201518058777\n","Epoch: 1 || Batch: 81 || unet loss: 1.7703003883361816 || dis loss: 0.684390664100647 || mse: 0.016085688024759293 | ssim:0.7871302366256714\n","Epoch: 1 || Batch: 82 || unet loss: 1.8605440855026245 || dis loss: 0.6340602040290833 || mse: 0.022980427369475365 | ssim:0.6750254034996033\n","Epoch: 1 || Batch: 83 || unet loss: 1.5875537395477295 || dis loss: 0.6866915225982666 || mse: 0.010285492055118084 | ssim:0.7977973222732544\n","Epoch: 1 || Batch: 84 || unet loss: 1.6604769229888916 || dis loss: 0.600855827331543 || mse: 0.021904876455664635 | ssim:0.695168137550354\n","Epoch: 1 || Batch: 85 || unet loss: 1.6913137435913086 || dis loss: 0.6161184906959534 || mse: 0.018467355519533157 | ssim:0.7294459342956543\n","Epoch: 1 || Batch: 86 || unet loss: 2.0360116958618164 || dis loss: 0.6262035369873047 || mse: 0.017273206263780594 | ssim:0.7352816462516785\n","Epoch: 1 || Batch: 87 || unet loss: 1.803398847579956 || dis loss: 0.6631892919540405 || mse: 0.017455078661441803 | ssim:0.6962113380432129\n","Epoch: 1 || Batch: 88 || unet loss: 2.0278196334838867 || dis loss: 0.5978055000305176 || mse: 0.02126009576022625 | ssim:0.727036714553833\n","Epoch: 1 || Batch: 89 || unet loss: 1.601633071899414 || dis loss: 0.5563729405403137 || mse: 0.022614412009716034 | ssim:0.7009493708610535\n","Epoch: 1 || Batch: 90 || unet loss: 1.688929557800293 || dis loss: 0.5782385468482971 || mse: 0.018894799053668976 | ssim:0.7529024481773376\n","Epoch: 1 || Batch: 91 || unet loss: 1.8033466339111328 || dis loss: 0.7012848258018494 || mse: 0.022067047655582428 | ssim:0.719580352306366\n","Epoch: 1 || Batch: 92 || unet loss: 1.8515275716781616 || dis loss: 0.5469094514846802 || mse: 0.03028727136552334 | ssim:0.6895562410354614\n","Epoch: 1 || Batch: 93 || unet loss: 2.004251718521118 || dis loss: 0.5351046323776245 || mse: 0.014608107507228851 | ssim:0.7729061841964722\n","Epoch: 1 || Batch: 94 || unet loss: 2.064896583557129 || dis loss: 0.5693423748016357 || mse: 0.018206000328063965 | ssim:0.7332162857055664\n","Epoch: 1 || Batch: 95 || unet loss: 1.519907832145691 || dis loss: 0.7654520869255066 || mse: 0.01862870156764984 | ssim:0.7644727230072021\n","Epoch: 1 || Batch: 96 || unet loss: 1.6155132055282593 || dis loss: 0.5340854525566101 || mse: 0.03213619068264961 | ssim:0.7097252607345581\n","Epoch: 1 || Batch: 97 || unet loss: 1.9628382921218872 || dis loss: 0.5075626373291016 || mse: 0.019320787861943245 | ssim:0.7237753868103027\n","Epoch: 1 || Batch: 98 || unet loss: 1.7234045267105103 || dis loss: 0.47248026728630066 || mse: 0.029008354991674423 | ssim:0.7234818339347839\n","Epoch: 1 || Batch: 99 || unet loss: 1.8895599842071533 || dis loss: 0.5995129346847534 || mse: 0.012825509533286095 | ssim:0.7489985823631287\n","Epoch: 1 || Batch: 100 || unet loss: 1.9755542278289795 || dis loss: 0.8137564659118652 || mse: 0.019069142639636993 | ssim:0.6927899122238159\n","Epoch: 1 || Batch: 101 || unet loss: 1.7581348419189453 || dis loss: 0.634463369846344 || mse: 0.025494053959846497 | ssim:0.7109897136688232\n","Epoch: 1 || Batch: 102 || unet loss: 2.01823091506958 || dis loss: 0.5786257982254028 || mse: 0.011452984064817429 | ssim:0.7305381298065186\n","Epoch: 1 || Batch: 103 || unet loss: 1.9411427974700928 || dis loss: 0.6267664432525635 || mse: 0.012364710681140423 | ssim:0.7581052780151367\n","Epoch: 1 || Batch: 104 || unet loss: 2.059551954269409 || dis loss: 0.5830001831054688 || mse: 0.021952113136649132 | ssim:0.7124587297439575\n","Epoch: 1 || Batch: 105 || unet loss: 1.7787243127822876 || dis loss: 0.7399126887321472 || mse: 0.020820435136556625 | ssim:0.724033772945404\n","\n","mse: + 0.021604829810489463 | ssim: 0.7062352485251877 | unet:1.8622939991501142\n","\n","Epoch: 2 || Batch: 1 || unet loss: 1.7296184301376343 || dis loss: 0.7431393265724182 || mse: 0.02395792119204998 | ssim:0.7174739241600037\n","Epoch: 2 || Batch: 2 || unet loss: 1.7471566200256348 || dis loss: 0.6382437348365784 || mse: 0.0246119424700737 | ssim:0.7091764211654663\n","Epoch: 2 || Batch: 3 || unet loss: 1.7109328508377075 || dis loss: 0.5505355596542358 || mse: 0.028774961829185486 | ssim:0.7480804324150085\n","Epoch: 2 || Batch: 4 || unet loss: 2.2204341888427734 || dis loss: 0.5587667226791382 || mse: 0.016479382291436195 | ssim:0.7220767736434937\n","Epoch: 2 || Batch: 5 || unet loss: 1.9469687938690186 || dis loss: 0.6152237057685852 || mse: 0.016364745795726776 | ssim:0.7376416921615601\n","Epoch: 2 || Batch: 6 || unet loss: 1.8821747303009033 || dis loss: 0.6592230796813965 || mse: 0.01484894659370184 | ssim:0.7719157934188843\n","Epoch: 2 || Batch: 7 || unet loss: 2.084491729736328 || dis loss: 0.7233152985572815 || mse: 0.019557759165763855 | ssim:0.7062646746635437\n","Epoch: 2 || Batch: 8 || unet loss: 1.5416768789291382 || dis loss: 0.6649041771888733 || mse: 0.0175006240606308 | ssim:0.8009998202323914\n","Epoch: 2 || Batch: 9 || unet loss: 1.7035633325576782 || dis loss: 0.5851485729217529 || mse: 0.03875134140253067 | ssim:0.696236252784729\n","Epoch: 2 || Batch: 10 || unet loss: 1.690386414527893 || dis loss: 0.5205134153366089 || mse: 0.034169770777225494 | ssim:0.7135843634605408\n","Epoch: 2 || Batch: 11 || unet loss: 1.847314715385437 || dis loss: 0.5954282283782959 || mse: 0.024066299200057983 | ssim:0.7245334386825562\n","Epoch: 2 || Batch: 12 || unet loss: 2.000293731689453 || dis loss: 0.6926187872886658 || mse: 0.017996305599808693 | ssim:0.6988915801048279\n","Epoch: 2 || Batch: 13 || unet loss: 1.9691611528396606 || dis loss: 0.6153162717819214 || mse: 0.01841079816222191 | ssim:0.7288987636566162\n","Epoch: 2 || Batch: 14 || unet loss: 1.9004813432693481 || dis loss: 0.796580970287323 || mse: 0.011142413131892681 | ssim:0.7316020727157593\n","Epoch: 2 || Batch: 15 || unet loss: 1.8360718488693237 || dis loss: 0.7998486757278442 || mse: 0.013294195756316185 | ssim:0.7561779022216797\n","Epoch: 2 || Batch: 16 || unet loss: 1.857759714126587 || dis loss: 0.5863193273544312 || mse: 0.028206130489706993 | ssim:0.7218095064163208\n","Epoch: 2 || Batch: 17 || unet loss: 1.947651743888855 || dis loss: 0.5449643135070801 || mse: 0.035194095224142075 | ssim:0.711080014705658\n","Epoch: 2 || Batch: 18 || unet loss: 1.8131049871444702 || dis loss: 0.6382360458374023 || mse: 0.020867682993412018 | ssim:0.7514069080352783\n","Epoch: 2 || Batch: 19 || unet loss: 2.105832099914551 || dis loss: 0.6704490780830383 || mse: 0.01864289864897728 | ssim:0.7026800513267517\n","Epoch: 2 || Batch: 20 || unet loss: 1.671345591545105 || dis loss: 0.7127798199653625 || mse: 0.01507237832993269 | ssim:0.7834107875823975\n","Epoch: 2 || Batch: 21 || unet loss: 1.6080724000930786 || dis loss: 0.6426230669021606 || mse: 0.043111175298690796 | ssim:0.7113463878631592\n","Epoch: 2 || Batch: 22 || unet loss: 1.8763797283172607 || dis loss: 0.7063037753105164 || mse: 0.025782018899917603 | ssim:0.714766263961792\n","Epoch: 2 || Batch: 23 || unet loss: 1.935570478439331 || dis loss: 0.7153733968734741 || mse: 0.014294220134615898 | ssim:0.7674564123153687\n","Epoch: 2 || Batch: 24 || unet loss: 1.7713855504989624 || dis loss: 0.6735070943832397 || mse: 0.03001801297068596 | ssim:0.7303193807601929\n","Epoch: 2 || Batch: 25 || unet loss: 1.7670717239379883 || dis loss: 0.7223122119903564 || mse: 0.035326991230249405 | ssim:0.7017819881439209\n","Epoch: 2 || Batch: 26 || unet loss: 1.5814096927642822 || dis loss: 0.7658834457397461 || mse: 0.040012553334236145 | ssim:0.6939977407455444\n","Epoch: 2 || Batch: 27 || unet loss: 2.0687999725341797 || dis loss: 0.7724354267120361 || mse: 0.01537376455962658 | ssim:0.6961857676506042\n","Epoch: 2 || Batch: 28 || unet loss: 1.9285591840744019 || dis loss: 0.8015186786651611 || mse: 0.016907384619116783 | ssim:0.753936231136322\n","Epoch: 2 || Batch: 29 || unet loss: 1.97024667263031 || dis loss: 0.6982262134552002 || mse: 0.022559072822332382 | ssim:0.7244963645935059\n","Epoch: 2 || Batch: 30 || unet loss: 1.983241319656372 || dis loss: 0.7627788782119751 || mse: 0.02608639746904373 | ssim:0.7125679850578308\n","Epoch: 2 || Batch: 31 || unet loss: 1.8426384925842285 || dis loss: 0.7630574703216553 || mse: 0.0264548659324646 | ssim:0.7389159202575684\n","Epoch: 2 || Batch: 32 || unet loss: 1.9122800827026367 || dis loss: 0.7456519603729248 || mse: 0.03574325516819954 | ssim:0.668663501739502\n","Epoch: 2 || Batch: 33 || unet loss: 1.8624587059020996 || dis loss: 0.7017664909362793 || mse: 0.018126679584383965 | ssim:0.7655062675476074\n","Epoch: 2 || Batch: 34 || unet loss: 1.8455983400344849 || dis loss: 0.6345208287239075 || mse: 0.04289042204618454 | ssim:0.6785988211631775\n","Epoch: 2 || Batch: 35 || unet loss: 1.6288506984710693 || dis loss: 0.6434164047241211 || mse: 0.032028086483478546 | ssim:0.6911858320236206\n","Epoch: 2 || Batch: 36 || unet loss: 2.05289888381958 || dis loss: 0.700941801071167 || mse: 0.024605736136436462 | ssim:0.7154557704925537\n","Epoch: 2 || Batch: 37 || unet loss: 1.669886589050293 || dis loss: 0.6267563700675964 || mse: 0.04910219833254814 | ssim:0.6755164861679077\n","Epoch: 2 || Batch: 38 || unet loss: 1.8928362131118774 || dis loss: 0.7558614611625671 || mse: 0.01952318660914898 | ssim:0.7316910624504089\n","Epoch: 2 || Batch: 39 || unet loss: 1.4974124431610107 || dis loss: 0.7079249024391174 || mse: 0.039881378412246704 | ssim:0.6808809041976929\n","Epoch: 2 || Batch: 40 || unet loss: 1.5937591791152954 || dis loss: 0.7512862086296082 || mse: 0.02256704866886139 | ssim:0.7666667699813843\n","Epoch: 2 || Batch: 41 || unet loss: 1.8862535953521729 || dis loss: 0.6940836906433105 || mse: 0.023257091641426086 | ssim:0.720024585723877\n","Epoch: 2 || Batch: 42 || unet loss: 2.1209218502044678 || dis loss: 0.7494167685508728 || mse: 0.025774605572223663 | ssim:0.7184317111968994\n","Epoch: 2 || Batch: 43 || unet loss: 1.5371912717819214 || dis loss: 0.7089027166366577 || mse: 0.02463902160525322 | ssim:0.7250630259513855\n","Epoch: 2 || Batch: 44 || unet loss: 1.9821430444717407 || dis loss: 0.7612450122833252 || mse: 0.024978479370474815 | ssim:0.714969277381897\n","Epoch: 2 || Batch: 45 || unet loss: 1.469512939453125 || dis loss: 0.6847708821296692 || mse: 0.037057824432849884 | ssim:0.7211344242095947\n","Epoch: 2 || Batch: 46 || unet loss: 1.423973560333252 || dis loss: 0.6579582691192627 || mse: 0.03327301889657974 | ssim:0.7323781847953796\n","Epoch: 2 || Batch: 47 || unet loss: 1.9063999652862549 || dis loss: 0.7089549899101257 || mse: 0.024813920259475708 | ssim:0.7146183252334595\n","Epoch: 2 || Batch: 48 || unet loss: 1.6256219148635864 || dis loss: 0.6922354698181152 || mse: 0.020454514771699905 | ssim:0.7283613681793213\n","Epoch: 2 || Batch: 49 || unet loss: 1.7804443836212158 || dis loss: 0.7376814484596252 || mse: 0.020775891840457916 | ssim:0.7230286598205566\n","Epoch: 2 || Batch: 50 || unet loss: 2.0642213821411133 || dis loss: 0.7631148099899292 || mse: 0.02477043867111206 | ssim:0.685156524181366\n","Epoch: 2 || Batch: 51 || unet loss: 1.5991241931915283 || dis loss: 0.7235885858535767 || mse: 0.02856660634279251 | ssim:0.6994211077690125\n","Epoch: 2 || Batch: 52 || unet loss: 2.049276351928711 || dis loss: 0.7741388082504272 || mse: 0.01827429234981537 | ssim:0.7063568830490112\n","Epoch: 2 || Batch: 53 || unet loss: 1.7975882291793823 || dis loss: 0.7456898093223572 || mse: 0.01661854237318039 | ssim:0.7595566511154175\n","Epoch: 2 || Batch: 54 || unet loss: 2.00303053855896 || dis loss: 0.755614161491394 || mse: 0.01619322970509529 | ssim:0.7282718420028687\n","Epoch: 2 || Batch: 55 || unet loss: 1.9324871301651 || dis loss: 0.8237860202789307 || mse: 0.015820728614926338 | ssim:0.7291437983512878\n","Epoch: 2 || Batch: 56 || unet loss: 1.8482195138931274 || dis loss: 0.8550806045532227 || mse: 0.028165753930807114 | ssim:0.7640496492385864\n","Epoch: 2 || Batch: 57 || unet loss: 1.8225430250167847 || dis loss: 0.771984338760376 || mse: 0.03335447236895561 | ssim:0.6662130951881409\n","Epoch: 2 || Batch: 58 || unet loss: 1.7678507566452026 || dis loss: 0.7970744371414185 || mse: 0.02047986537218094 | ssim:0.7610898017883301\n","Epoch: 2 || Batch: 59 || unet loss: 1.6983988285064697 || dis loss: 0.7174645662307739 || mse: 0.03308912366628647 | ssim:0.6870187520980835\n","Epoch: 2 || Batch: 60 || unet loss: 1.5339218378067017 || dis loss: 0.761186420917511 || mse: 0.01760498806834221 | ssim:0.7098678350448608\n","Epoch: 2 || Batch: 61 || unet loss: 1.846533179283142 || dis loss: 0.8013582825660706 || mse: 0.01444164291024208 | ssim:0.7339377403259277\n","Epoch: 2 || Batch: 62 || unet loss: 1.8602473735809326 || dis loss: 0.8502416014671326 || mse: 0.02333705686032772 | ssim:0.6608061790466309\n","Epoch: 2 || Batch: 63 || unet loss: 1.9569079875946045 || dis loss: 0.7688718438148499 || mse: 0.024269074201583862 | ssim:0.7109782695770264\n","Epoch: 2 || Batch: 64 || unet loss: 1.9427412748336792 || dis loss: 0.7805469036102295 || mse: 0.016105491667985916 | ssim:0.7294712066650391\n","Epoch: 2 || Batch: 65 || unet loss: 1.7740886211395264 || dis loss: 0.7721074819564819 || mse: 0.013605642132461071 | ssim:0.7686634063720703\n","Epoch: 2 || Batch: 66 || unet loss: 1.9508379697799683 || dis loss: 0.760012149810791 || mse: 0.015124890953302383 | ssim:0.7272471785545349\n","Epoch: 2 || Batch: 67 || unet loss: 2.0718531608581543 || dis loss: 0.7873655557632446 || mse: 0.01832396537065506 | ssim:0.7084028124809265\n","Epoch: 2 || Batch: 68 || unet loss: 1.9336796998977661 || dis loss: 0.7705474495887756 || mse: 0.024098044261336327 | ssim:0.734468400478363\n","Epoch: 2 || Batch: 69 || unet loss: 1.9024578332901 || dis loss: 0.7927312850952148 || mse: 0.02597828023135662 | ssim:0.7303761839866638\n","Epoch: 2 || Batch: 70 || unet loss: 1.6774077415466309 || dis loss: 0.7461932301521301 || mse: 0.0225360244512558 | ssim:0.7516255378723145\n","Epoch: 2 || Batch: 71 || unet loss: 1.50563645362854 || dis loss: 0.7025341987609863 || mse: 0.03124925307929516 | ssim:0.7238890528678894\n","Epoch: 2 || Batch: 72 || unet loss: 1.871497631072998 || dis loss: 0.7144660353660583 || mse: 0.01993698999285698 | ssim:0.7138301730155945\n","Epoch: 2 || Batch: 73 || unet loss: 1.6465901136398315 || dis loss: 0.6850559711456299 || mse: 0.021502044051885605 | ssim:0.7173681259155273\n","Epoch: 2 || Batch: 74 || unet loss: 1.7116117477416992 || dis loss: 0.7454385757446289 || mse: 0.01834239438176155 | ssim:0.74676913022995\n","Epoch: 2 || Batch: 75 || unet loss: 1.8106868267059326 || dis loss: 0.7653025984764099 || mse: 0.0210963636636734 | ssim:0.7033128142356873\n","Epoch: 2 || Batch: 76 || unet loss: 1.8508470058441162 || dis loss: 0.7425676584243774 || mse: 0.01740344427525997 | ssim:0.7325540781021118\n","Epoch: 2 || Batch: 77 || unet loss: 1.6721546649932861 || dis loss: 0.6956285238265991 || mse: 0.019412720575928688 | ssim:0.713125467300415\n","Epoch: 2 || Batch: 78 || unet loss: 1.6956983804702759 || dis loss: 0.6884997487068176 || mse: 0.02015167847275734 | ssim:0.7441084384918213\n","Epoch: 2 || Batch: 79 || unet loss: 2.0500681400299072 || dis loss: 0.70588618516922 || mse: 0.014367091469466686 | ssim:0.7275539636611938\n","Epoch: 2 || Batch: 80 || unet loss: 1.6502151489257812 || dis loss: 0.7483825087547302 || mse: 0.017501920461654663 | ssim:0.7375531196594238\n","Epoch: 2 || Batch: 81 || unet loss: 1.7767802476882935 || dis loss: 0.7789760828018188 || mse: 0.015554046258330345 | ssim:0.7756799459457397\n","Epoch: 2 || Batch: 82 || unet loss: 1.672499656677246 || dis loss: 0.7086305618286133 || mse: 0.023306678980588913 | ssim:0.6945500373840332\n","Epoch: 2 || Batch: 83 || unet loss: 1.6189634799957275 || dis loss: 0.6942441463470459 || mse: 0.013711532577872276 | ssim:0.8093540668487549\n","Epoch: 2 || Batch: 84 || unet loss: 1.6798324584960938 || dis loss: 0.6276340484619141 || mse: 0.029664169996976852 | ssim:0.6916884183883667\n","Epoch: 2 || Batch: 85 || unet loss: 1.5181193351745605 || dis loss: 0.7326246500015259 || mse: 0.017888329923152924 | ssim:0.7308220863342285\n","Epoch: 2 || Batch: 86 || unet loss: 1.69566810131073 || dis loss: 0.816291093826294 || mse: 0.01806240901350975 | ssim:0.732932984828949\n","Epoch: 2 || Batch: 87 || unet loss: 1.9296753406524658 || dis loss: 0.8279328942298889 || mse: 0.016689077019691467 | ssim:0.7065484523773193\n","Epoch: 2 || Batch: 88 || unet loss: 1.9566924571990967 || dis loss: 0.8021982908248901 || mse: 0.02638974040746689 | ssim:0.7128170728683472\n","Epoch: 2 || Batch: 89 || unet loss: 1.5705304145812988 || dis loss: 0.736270010471344 || mse: 0.03248434141278267 | ssim:0.6759947538375854\n","Epoch: 2 || Batch: 90 || unet loss: 1.8058561086654663 || dis loss: 0.8172115683555603 || mse: 0.01834160089492798 | ssim:0.7574033141136169\n","Epoch: 2 || Batch: 91 || unet loss: 2.0238592624664307 || dis loss: 0.8332496881484985 || mse: 0.012624646537005901 | ssim:0.7310718297958374\n","Epoch: 2 || Batch: 92 || unet loss: 1.849556565284729 || dis loss: 0.8567540645599365 || mse: 0.023055365309119225 | ssim:0.7210060954093933\n","Epoch: 2 || Batch: 93 || unet loss: 1.9931559562683105 || dis loss: 0.858138918876648 || mse: 0.022174736484885216 | ssim:0.7343075275421143\n","Epoch: 2 || Batch: 94 || unet loss: 1.964819312095642 || dis loss: 0.8381979465484619 || mse: 0.02603888139128685 | ssim:0.7230525016784668\n","Epoch: 2 || Batch: 95 || unet loss: 1.3467730283737183 || dis loss: 0.7320759892463684 || mse: 0.026371752843260765 | ssim:0.7389929294586182\n","Epoch: 2 || Batch: 96 || unet loss: 1.547776222229004 || dis loss: 0.701481282711029 || mse: 0.03312297165393829 | ssim:0.7135605812072754\n","Epoch: 2 || Batch: 97 || unet loss: 1.894771933555603 || dis loss: 0.7533616423606873 || mse: 0.02084570750594139 | ssim:0.715238094329834\n","Epoch: 2 || Batch: 98 || unet loss: 1.7486300468444824 || dis loss: 0.7418443560600281 || mse: 0.021347541362047195 | ssim:0.7300697565078735\n","Epoch: 2 || Batch: 99 || unet loss: 1.5523669719696045 || dis loss: 0.7198910713195801 || mse: 0.027720212936401367 | ssim:0.711281955242157\n","Epoch: 2 || Batch: 100 || unet loss: 1.8705745935440063 || dis loss: 0.7461888790130615 || mse: 0.03216498717665672 | ssim:0.6779167056083679\n","Epoch: 2 || Batch: 101 || unet loss: 1.8031409978866577 || dis loss: 0.7305651307106018 || mse: 0.027444487437605858 | ssim:0.6836845874786377\n","Epoch: 2 || Batch: 102 || unet loss: 2.0398082733154297 || dis loss: 0.7737439274787903 || mse: 0.021798891946673393 | ssim:0.7000784873962402\n","Epoch: 2 || Batch: 103 || unet loss: 1.6192944049835205 || dis loss: 0.704188346862793 || mse: 0.02413223683834076 | ssim:0.7491613626480103\n","Epoch: 2 || Batch: 104 || unet loss: 2.0106191635131836 || dis loss: 0.7249209880828857 || mse: 0.01750459149479866 | ssim:0.7343174815177917\n","Epoch: 2 || Batch: 105 || unet loss: 1.7474603652954102 || dis loss: 0.7517890930175781 || mse: 0.01846574805676937 | ssim:0.7302688360214233\n","\n","mse: + 0.02332034104345542 | ssim: 0.7164705063936845 | unet:1.7921121435345344\n","\n","Epoch: 3 || Batch: 1 || unet loss: 1.8228790760040283 || dis loss: 0.794875979423523 || mse: 0.02431333437561989 | ssim:0.7007371187210083\n","Epoch: 3 || Batch: 2 || unet loss: 1.8835325241088867 || dis loss: 0.7147974371910095 || mse: 0.01923520117998123 | ssim:0.7101994752883911\n","Epoch: 3 || Batch: 3 || unet loss: 1.648237943649292 || dis loss: 0.697464108467102 || mse: 0.02153836563229561 | ssim:0.7479451894760132\n","Epoch: 3 || Batch: 4 || unet loss: 2.0439908504486084 || dis loss: 0.7012802958488464 || mse: 0.022468257695436478 | ssim:0.7274866104125977\n","Epoch: 3 || Batch: 5 || unet loss: 1.9021964073181152 || dis loss: 0.7216243743896484 || mse: 0.017316196113824844 | ssim:0.742562472820282\n","Epoch: 3 || Batch: 6 || unet loss: 1.9456372261047363 || dis loss: 0.7341527938842773 || mse: 0.02618715912103653 | ssim:0.7578942775726318\n","Epoch: 3 || Batch: 7 || unet loss: 1.9241011142730713 || dis loss: 0.7234727740287781 || mse: 0.025480028241872787 | ssim:0.6804217100143433\n","Epoch: 3 || Batch: 8 || unet loss: 1.7097160816192627 || dis loss: 0.7562587857246399 || mse: 0.015853095799684525 | ssim:0.7734370231628418\n","Epoch: 3 || Batch: 9 || unet loss: 1.5751408338546753 || dis loss: 0.6801510453224182 || mse: 0.03181185573339462 | ssim:0.6978273391723633\n","Epoch: 3 || Batch: 10 || unet loss: 1.6353158950805664 || dis loss: 0.6578702926635742 || mse: 0.022710105404257774 | ssim:0.7421001195907593\n","Epoch: 3 || Batch: 11 || unet loss: 1.9553829431533813 || dis loss: 0.6622986793518066 || mse: 0.01632203720510006 | ssim:0.7430833578109741\n","Epoch: 3 || Batch: 12 || unet loss: 1.7515673637390137 || dis loss: 0.6463443636894226 || mse: 0.02020450495183468 | ssim:0.6816200017929077\n","Epoch: 3 || Batch: 13 || unet loss: 1.8838568925857544 || dis loss: 0.689028799533844 || mse: 0.016488714143633842 | ssim:0.7518256902694702\n","Epoch: 3 || Batch: 14 || unet loss: 1.5465922355651855 || dis loss: 0.7069814205169678 || mse: 0.02716943994164467 | ssim:0.6945605278015137\n","Epoch: 3 || Batch: 15 || unet loss: 1.4730024337768555 || dis loss: 0.7138017416000366 || mse: 0.022707980126142502 | ssim:0.7550113201141357\n","Epoch: 3 || Batch: 16 || unet loss: 2.0470900535583496 || dis loss: 0.6852906942367554 || mse: 0.010741576552391052 | ssim:0.7398039698600769\n","Epoch: 3 || Batch: 17 || unet loss: 1.6980351209640503 || dis loss: 0.577880859375 || mse: 0.03553328663110733 | ssim:0.7010967135429382\n","Epoch: 3 || Batch: 18 || unet loss: 1.9189385175704956 || dis loss: 0.656410813331604 || mse: 0.02166271023452282 | ssim:0.741362988948822\n","Epoch: 3 || Batch: 19 || unet loss: 1.8311692476272583 || dis loss: 0.7576451301574707 || mse: 0.016342192888259888 | ssim:0.7311961054801941\n","Epoch: 3 || Batch: 20 || unet loss: 1.3416767120361328 || dis loss: 0.7838453650474548 || mse: 0.02214936725795269 | ssim:0.7622002363204956\n","Epoch: 3 || Batch: 21 || unet loss: 1.5694185495376587 || dis loss: 0.6728826761245728 || mse: 0.03585853800177574 | ssim:0.7134801149368286\n","Epoch: 3 || Batch: 22 || unet loss: 1.9574322700500488 || dis loss: 0.6923186182975769 || mse: 0.01638949289917946 | ssim:0.7210227251052856\n","Epoch: 3 || Batch: 23 || unet loss: 1.797327995300293 || dis loss: 0.6986504197120667 || mse: 0.013190480880439281 | ssim:0.743488073348999\n","Epoch: 3 || Batch: 24 || unet loss: 1.6729923486709595 || dis loss: 0.8548493385314941 || mse: 0.02522757463157177 | ssim:0.7206003069877625\n","Epoch: 3 || Batch: 25 || unet loss: 2.1022496223449707 || dis loss: 0.7915897965431213 || mse: 0.02252950333058834 | ssim:0.6750472784042358\n","Epoch: 3 || Batch: 26 || unet loss: 1.8971441984176636 || dis loss: 0.8265023231506348 || mse: 0.021858755499124527 | ssim:0.7070201635360718\n","Epoch: 3 || Batch: 27 || unet loss: 1.9615552425384521 || dis loss: 0.777473509311676 || mse: 0.015391683205962181 | ssim:0.7055797576904297\n"]}],"source":["epochs = 50\n","torch.autograd.set_detect_anomaly(True)\n","train(epochs)"]},{"cell_type":"markdown","metadata":{"id":"3vXFZE36R-C_"},"source":["Saving weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZKT5tEJmAABT"},"outputs":[],"source":["path_of_generator_weight = 'weight/generator.pth'  #path for storing the weights of genertaor\n","path_of_discriminator_weight = 'weight/discriminator.pth'  #path for storing the weights of discriminator\n","DUNet.save_weight(path_of_generator_weight,path_of_discriminator_weight)"]},{"cell_type":"markdown","metadata":{"id":"AWqkb8epSIup"},"source":["Saving weights"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"aPjwtGKeAABV"},"outputs":[],"source":["path_of_generator_weight = 'hj_train_211201_lr0.00001/generator_0.pth'  #path where the weights of genertaor are stored\n","path_of_discriminator_weight = 'hj_train_211201_lr0.00001/discriminator_0.pth'  #path where the weights of discriminator are stored\n","DUNet.load(path_of_generator_weight, path_of_discriminator_weight)"]},{"cell_type":"markdown","metadata":{"id":"3MAztif9SRC_"},"source":["Runing the model on test data"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"rEMIiCj3AABe"},"outputs":[],"source":["def to_tensor(img):\n","    img_t = F6.to_tensor(img).float()\n","    return img_t\n","\n","def postprocess(img):\n","        img = img * 255.0\n","        img = img.permute(0, 2, 3, 1)\n","        return img.int()"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"jru-qj5JH9bf"},"outputs":[],"source":["from PIL import Image"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"7Bb-OyJTAABh"},"outputs":[],"source":["path_of_test_hazy_images = 'O-Haze/train/haze/*'\n","path_for_resultant_dehaze_images = 'hj_results_0.00001_00/train_'\n","if not os.path.exists(path_for_resultant_dehaze_images.split('/')[0]):\n","    os.mkdir(path_for_resultant_dehaze_images.split('/')[0])\n","image_paths_test_hazy=glob.glob(path_of_test_hazy_images)\n","\n","for i in range(len(image_paths_test_hazy)):\n","    haze_image = cv2.imread(image_paths_test_hazy[i])\n","    haze_image = Image.fromarray(haze_image)\n","    haze_image = haze_image.resize((512,512), resample=PIL.Image.BICUBIC)\n","    haze_image = np.array(haze_image)\n","    haze_image = cv2.cvtColor(haze_image, cv2.COLOR_BGR2YCrCb)\n","    haze_image = to_tensor(haze_image).cuda()\n","    haze_image = haze_image.reshape(1,3,512,512)\n","\n","    dehaze_image = DUNet.predict(haze_image) \n","    \n","    dehaze_image = postprocess(dehaze_image)[0]\n","    dehaze_image = dehaze_image.cpu().detach().numpy()\n","    dehaze_image = dehaze_image.astype('uint8')\n","    dehaze_image = dehaze_image.reshape(512,512,3)\n","    dehaze_image = cv2.cvtColor(dehaze_image, cv2.COLOR_YCrCb2BGR)\n","    cv2.imwrite(path_for_resultant_dehaze_images+str(i+1)+'.png', dehaze_image)"]},{"cell_type":"markdown","metadata":{"id":"YcYTCrl_SZGz"},"source":["Calculating the metrices i.e PSNR and SSIM for testing data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jgJC-JMuAABl"},"outputs":[],"source":["class EdgeAccuracy(nn.Module):\n","    \"\"\"\n","    Measures the accuracy of the edge map\n","    \"\"\"\n","    def __init__(self, threshold=0.5):\n","        super().__init__()\n","        self.threshold = threshold\n","\n","    def __call__(self, inputs, outputs):\n","        labels = (inputs > self.threshold)\n","        outputs = (outputs > self.threshold)\n","\n","        relevant = torch.sum(labels.float())\n","        selected = torch.sum(outputs.float())\n","\n","        if relevant == 0 and selected == 0:\n","            return 1, 1\n","\n","        true_positive = ((outputs == labels) * labels).float()\n","        recall = torch.sum(true_positive) / (relevant + 1e-8)\n","        precision = torch.sum(true_positive) / (selected + 1e-8)\n","\n","        return precision, recall\n","\n","\n","class PSNR(nn.Module):\n","    def __init__(self, max_val=0):\n","        super().__init__()\n","\n","        base10 = torch.log(torch.tensor(10.0))\n","        max_val = torch.tensor(max_val).float()\n","\n","        self.register_buffer('base10', base10)\n","        self.register_buffer('max_val', 20 * torch.log(max_val) / base10)\n","\n","    def __call__(self, a, b):\n","        mse = torch.mean((a.float() - b.float()) ** 2)\n","    \n","        if mse == 0:\n","            return 0\n","\n","        return 1.0 / mse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fsxd9gSxAABm"},"outputs":[],"source":["def gaussian(window_size, sigma):\n","    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n","    return gauss/gauss.sum()\n","\n","def create_window(window_size, channel):\n","    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n","    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n","    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n","    return window\n","\n","def _ssim(img1, img2, window, window_size, channel, size_average = True):\n","    mu1 = F9.conv2d(img1, window, padding = window_size//2, groups = channel)\n","    mu2 = F9.conv2d(img2, window, padding = window_size//2, groups = channel)\n","\n","    mu1_sq = mu1.pow(2)\n","    mu2_sq = mu2.pow(2)\n","    mu1_mu2 = mu1*mu2\n","\n","    sigma1_sq = F9.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n","    sigma2_sq = F9.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n","    sigma12 = F9.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n","\n","    C1 = 0.01**2\n","    C2 = 0.03**2\n","\n","    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n","\n","    if size_average:\n","        return ssim_map.mean()\n","    else:\n","        return ssim_map.mean(1).mean(1).mean(1)\n","\n","class SSIM(torch.nn.Module):\n","    def __init__(self, window_size = 11, size_average = True):\n","        super(SSIM, self).__init__()\n","        self.window_size = window_size\n","        self.size_average = size_average\n","        self.channel = 1\n","        self.window = create_window(window_size, self.channel)\n","\n","    def forward(self, img1, img2):\n","        (_, channel, _, _) = img1.size()\n","\n","        if channel == self.channel and self.window.data.type() == img1.data.type():\n","            window = self.window\n","        else:\n","            window = create_window(self.window_size, channel)\n","            \n","            if img1.is_cuda:\n","                window = window.cuda(img1.get_device())\n","            window = window.type_as(img1)\n","            \n","            self.window = window\n","            self.channel = channel\n","\n","\n","        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n","\n","def ssim(img1, img2, window_size = 11, size_average = True):\n","    (_, channel, _, _) = img1.size()\n","    window = create_window(window_size, channel)\n","    \n","    if img1.is_cuda:\n","        window = window.cuda(img1.get_device())\n","    window = window.type_as(img1)\n","    \n","    return _ssim(img1, img2, window, window_size, channel, size_average)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9hTzS1wUAABq"},"outputs":[],"source":["ssim = SSIM(window_size = 11)\n","psnr = PSNR()\n","psnr_val = 0\n","psnr_val = 0.0\n","final_ssim = 0\n","\n","path_of_test_hazy_images = 'test/haze/*.png'\n","path_of_test_gt_images = 'test/gt/*.png'\n","path_for_resultant_dehaze_images = 'test/result/'\n","\n","image_paths_test_hazy=glob.glob(path_of_test_hazy_images)\n","image_paths_test_gt=glob.glob(path_of_test_gt_images)\n","\n","for i in range(len(image_paths_test_hazy)):\n","    im1 = cv2.imread(image_paths_GT[i])\n","    im1 = Image.fromarray(im1)\n","    im1 = im1.resize((512,512), resample=PIL.Image.BICUBIC)\n","    im1 = np.array(im1)\n","    im2 = cv2.imread('Results/experiment yrcrcb/new/outdoor/' + str(i+50)+'.png')\n","\n","    im1 = to_tensor(im1).reshape(1,3,512,512)\n","    im2 = to_tensor(im2).reshape(1,3,512,512)\n","    \n","    psnr_val = psnr(im1, im2)\n","    final_psnr = final_psnr + 10*np.log10((psnr_val))\n","    final_ssim = final_ssim + ssim(im1, im2)\n","\n","\n","print(final_ssim/5.0, final_psnr/5.0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WGWLUya4AAB0"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Single_Image_Dehazing.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00bd30886cab4fe682e25a897b7dde9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2182e0fd245b47c6a4b2effc75772271":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"39b1407cce964ccc80dde8685c296bb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fea42f5b82c464895c39da4c89bc001":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b67b16690dc8453faf8c4b5e3866d3db","placeholder":"","style":"IPY_MODEL_39b1407cce964ccc80dde8685c296bb7","value":" 548M/548M [02:14&lt;00:00, 4.26MB/s]"}},"b67b16690dc8453faf8c4b5e3866d3db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d34e39b5242f4a9da3e0d1bc428b9e13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_00bd30886cab4fe682e25a897b7dde9c","max":574673361,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2182e0fd245b47c6a4b2effc75772271","value":574673361}},"ebe9a67a932540f5915ea51ec0a5270a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d34e39b5242f4a9da3e0d1bc428b9e13","IPY_MODEL_5fea42f5b82c464895c39da4c89bc001"],"layout":"IPY_MODEL_f7c88cdd25194de19710363de98990aa"}},"f7c88cdd25194de19710363de98990aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
